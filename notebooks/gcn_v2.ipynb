{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USE PYG ENVIRONMENT!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch_geometric\n",
    "\n",
    "# # Optional dependencies:\n",
    "# !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ### USE PYG ENVIRONMENT!!!!\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126 --force-reinstall\n",
    "\n",
    "# # %%\n",
    "# # Install required packages\n",
    "# import os, torch\n",
    "\n",
    "# os.environ['TORCH'] = torch.__version__\n",
    "# !pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
    "# !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "# # !pip install sentence_transformers\n",
    "# # !pip3 install fuzzywuzzy[speedup]\n",
    "# # !pip install captum\n",
    "# !pip install torch-sparse\n",
    "# !pip install torch-scatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda activate pygenv \n",
    "# !pip3 install torch==2.5.0+cu124 --index-url https://download.pytorch.org/whl/cu124 --force-reinstall\n",
    "# !pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-2.5.0+cu124.html --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "\n",
    "# Check for CUDA availability and set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 80085\n",
    "torch.manual_seed(random_seed)\t\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "from torch_geometric.nn.models import Node2Vec\n",
    "\n",
    "\n",
    "### load graph data \n",
    "import pickle\n",
    "\n",
    "with open('../data/graphs/linegraph_tg.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "ebc = data.x.detach().cpu().numpy()\n",
    "\n",
    "model = Node2Vec(data.edge_index, embedding_dim=64, walk_length=20,\n",
    "                    context_size=10, walks_per_node=10,\n",
    "                    num_negative_samples=1, p=2.0, q=0.5, sparse=True)\n",
    "\n",
    "model.load_state_dict(torch.load('../data/node2vec_2.pt', weights_only=True))\n",
    "\n",
    "n2v_weights = model.embedding.weight.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def stratified_split(data, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    \"\"\"Splits data into train, validation, and test sets, stratifying by y > 0.\"\"\"\n",
    "\n",
    "    # Create a boolean mask for nodes where y > 0\n",
    "    positive_mask = data.y > 0\n",
    "\n",
    "    # Get indices of positive and negative nodes\n",
    "    positive_indices = positive_mask.nonzero(as_tuple=False).squeeze()\n",
    "    negative_indices = (~positive_mask).nonzero(as_tuple=False).squeeze()\n",
    "\n",
    "    # Split positive indices\n",
    "    pos_train_idx, pos_temp_idx = train_test_split(positive_indices, train_size=train_ratio, random_state=random_seed)  # Adjust random_state for consistent splits\n",
    "    pos_val_idx, pos_test_idx = train_test_split(pos_temp_idx, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=random_seed)\n",
    "\n",
    "    # Split negative indices\n",
    "    neg_train_idx, neg_temp_idx = train_test_split(negative_indices, train_size=train_ratio, random_state=random_seed)\n",
    "    neg_val_idx, neg_test_idx = train_test_split(neg_temp_idx, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=random_seed)\n",
    "\n",
    "    # Combine indices\n",
    "    train_idx = torch.cat([pos_train_idx, neg_train_idx])\n",
    "    val_idx = torch.cat([pos_val_idx, neg_val_idx])\n",
    "    test_idx = torch.cat([pos_test_idx, neg_test_idx])\n",
    "\n",
    "    # Create masks\n",
    "    train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "    train_mask[train_idx] = True\n",
    "    val_mask[val_idx] = True\n",
    "    test_mask[test_idx] = True\n",
    "\n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x = torch.tensor(n2v_weights, dtype=torch.float32)\n",
    "data.edge_index = data.edge_index.contiguous()\n",
    "data.x = data.x.contiguous()\n",
    "data.y = data.y.contiguous()\n",
    "\n",
    "import os, torch\n",
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "data = stratified_split(data)\n",
    "\n",
    "\n",
    "# Set the input nodes for the loader\n",
    "# loader = NeighborLoader(data, batch_size=batch_size,\n",
    "#                         shuffle=True, \n",
    "#                         num_neighbors=[-1]*100,\n",
    "#                         input_nodes=train_nodes)\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(80085)\n",
    "        self.conv1 = GCNConv(data.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin =  Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64).to(device) # Move model to device\n",
    "\n",
    "# Move data to device\n",
    "data.x = data.x.to(device)\n",
    "data.edge_index = data.edge_index.to(device)\n",
    "if hasattr(data, 'y'): # Check if 'y' exists and move it. Important for heterogeneous graphs.\n",
    "    data.y = data.y.to(device)\n",
    "if hasattr(data, 'train_mask'):\n",
    "    data.train_mask = data.train_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'gcn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('gcn.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=5e-4)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, int(1e+6)):\n",
    "    loss = train()\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'gcn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.val_mask], data.y[data.val_mask])  # Compute the loss solely based on the test nodes.\n",
    "    return loss, out\n",
    "\n",
    "loss, out = test()\n",
    "\n",
    "## get indices of val nodes with y > 0\n",
    "val_idx = data.val_mask.nonzero(as_tuple=False).squeeze()\n",
    "val_idx = val_idx[data.y[data.val_mask] > 0]\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(data.y[val_idx].detach().cpu().numpy(), out[val_idx].detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Loss: {loss:.4f}')\n",
    "y_over_0 = data.y[data.val_mask].detach().cpu().numpy() ; y_over_0 = y_over_0[y_over_0 > 0]\n",
    "out_over_0 = out[data.val_mask].detach().cpu().numpy() ; out_over_0 = out_over_0[out_over_0 > min(y_over_0)]\n",
    "sns.histplot(out_over_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(y_over_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "non_zero = data.y[data.y > 0]\n",
    "non_zero_pred = model(data.x, data.edge_index)[data.y > 0]\n",
    "non_zero_pred = non_zero_pred.detach().cpu().numpy()\n",
    "sns.histplot(non_zero_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(non_zero.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def test_r2():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    r2 = r2_score(data.y[data.test_mask].detach().cpu().numpy(), out[data.test_mask].detach().cpu().numpy())\n",
    "    return r2\n",
    "\n",
    "print(f'Loss: {test():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get train_mask indices\n",
    "train_indices = data.train_mask.nonzero(as_tuple=False).squeeze()\n",
    "train_indices = train_indices.detach().cpu().numpy()\n",
    "\n",
    "ebc_train = ebc[train_indices]\n",
    "y_train = data.y[train_indices].detach().cpu().numpy()\n",
    "\n",
    "### get test_mask indices\n",
    "test_indices = data.test_mask.nonzero(as_tuple=False).squeeze()\n",
    "test_indices = test_indices.detach().cpu().numpy()\n",
    "\n",
    "ebc_test = ebc[test_indices]\n",
    "y_test = data.y[test_indices].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/graphs/linegraph_nx.pkl', 'rb') as f:\n",
    "    graph = pickle.load(f)\n",
    "\n",
    "ebc, y = [], []\n",
    "\n",
    "import networkx as nx\t\n",
    "for _, node in graph.nodes(data=True):\n",
    "    if node['aadt'] > 0:\n",
    "        ebc.append(node['bc'])\n",
    "        y.append(node['aadt'])\n",
    "\n",
    "ebc = np.array(ebc)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ebc, y, test_size=0.2)\n",
    "\n",
    "reg = LinearRegression().fit(X_train.reshape(-1,1), y_train)\n",
    "print(reg.score(X_test.reshape(-1,1 ), y_test))\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, reg.predict(X_test.reshape(-1,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()  # Clear gradients\n",
    "#     losses = []\n",
    "#     first = True\n",
    "#     for batch in loader:\n",
    "#         batch = batch.to(device) # Move batch to device\n",
    "#         out = model(batch.x, batch.edge_index)\n",
    "#         loss = criterion(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "#         loss.backward()  # Backward pass.\n",
    "#         optimizer.step()\n",
    "#         losses.append(loss.item())\n",
    "#     return torch.tensor(losses).mean().item()\n",
    "\n",
    "\n",
    "# for epoch in range(1, 10000):\n",
    "#     loss = train()\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f'Epoch: {epoch:03d}, Loss: {loss}', 'improvement:', prev_loss-loss)\n",
    "#     prev_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
