{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b78ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "\n",
    "import os, torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "from torch_geometric.nn.models import Node2Vec\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "GCNConv._orig_propagate = GCNConv.propagate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.explain import GNNExplainer, Explainer\n",
    "from models import *\n",
    "from tg_functions import *\n",
    "from bike_functions import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy \n",
    "\n",
    "dropout_p = 0.5\n",
    "use_gat = True\n",
    "bins = [int(i) for i in os.getenv(\"BINS\", \"400 800 1300 2100 3000 3700 4700 7020 9660\").split(' ')]\n",
    "\n",
    "bins = torch.tensor(bins, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "hidden_c = 200\n",
    "num_layers = 0\n",
    "random_seed = 100\n",
    "nh = 1\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "numpy.random.seed(random_seed)\n",
    "\n",
    "graph_num = 17  # Replace with your graph number\n",
    "\n",
    "model_name = 'rich-sun-141' # Replace with your model name\n",
    "\n",
    "weight_prefix = 'best_accuracy'  # Replace with your weight prefix\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\", flush = True)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\", flush = True)\n",
    "\n",
    "# device = 'cpu'\n",
    "\n",
    "with open(f'../data/graphs/{graph_num}/linegraph_tg.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data.edge_index = data.edge_index.contiguous()\n",
    "data.x = data.x.contiguous()\n",
    "data.y = data.y.contiguous()\n",
    "\n",
    "data = stratified_split(data = data , random_seed = random_seed)\n",
    "\n",
    "# --- Model Instantiation ---\n",
    "model = GAT(hidden_c, num_layers, random_seed, bins, data, nh).to(device) if use_gat else GCN(hidden_c, num_layers, random_seed, bins, data).to(device)\n",
    "\n",
    "if use_gat == 'MLP':\n",
    "    model = MLP(hidden_c, num_layers, random_seed, bins, data, nh).to(device)\n",
    "\n",
    "# Load the model with the GCN class\n",
    "model = torch.load(f'../data/graphs/{graph_num}/models/{model_name}.pt', map_location=device)\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(f'../data/graphs/{graph_num}/models/{model_name}_{weight_prefix}.pt', map_location=device))\n",
    "model.eval()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee392b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index = data.edge_index.contiguous()\n",
    "data.x = data.x.contiguous()\n",
    "data.y = data.y.contiguous()\n",
    "print(data.x.shape, data.edge_index.shape, data.y.shape, flush = True)\n",
    "data = stratified_split(data)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "from torch_geometric.explain import GNNExplainer, Explainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=100),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type=None,\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcd1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv(f'../data/graphs/{graph_num}/node_features.csv')\n",
    "print(len(df_.columns))\n",
    "len(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1cc7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data.val_mask.squeeze() & (data.y > 0).squeeze()\n",
    "node_idx = 8\n",
    "node_idx = torch.where(mask)[0][node_idx].item()  # Get the first node index where mask is True\n",
    "print(f\"Node index for explanation: {node_idx}\", flush=True)\n",
    "explanation = explainer(data.x, data.edge_index, index=node_idx)\n",
    "pred = model(data.x, data.edge_index)\n",
    "pred = pred.argmax(dim=1)\n",
    "print(f\"Node {node_idx} prediction: {pred[node_idx].item()}\", flush=True)\n",
    "print(f\"Node {node_idx} true label: {torch.bucketize(data.y[node_idx].item(),bins)}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = max(data.y[mask])\n",
    "## get index of node with max val \n",
    "max_idx = torch.where(data.y[mask] == max_val)[0][0].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import subgraph\n",
    "import torch\n",
    "\n",
    "def get_node_k_hop_subgraph(data: Data, node_idx: int, k_hop: int):\n",
    "    \"\"\"\n",
    "    Returns the k-hop neighborhood subgraph of a node.\n",
    "\n",
    "    Parameters:\n",
    "    - data (torch_geometric.data.Data): PyG graph object\n",
    "    - node_idx (int): Index of the center node\n",
    "    - k_hop (int): Number of hops to include in the neighborhood\n",
    "\n",
    "    Returns:\n",
    "    - sub_nodes (torch.Tensor): Tensor of node indices in the subgraph\n",
    "    - sub_edges (torch.Tensor): 2 x N tensor of edge indices in the subgraph\n",
    "    \"\"\"\n",
    "    # Initialize with the center node\n",
    "    visited = set([node_idx])\n",
    "    current_frontier = set([node_idx])\n",
    "    edge_index = data.edge_index\n",
    "\n",
    "    for _ in range(k_hop):\n",
    "        next_frontier = set()\n",
    "        for idx in current_frontier:\n",
    "            mask = (edge_index[0] == idx) | (edge_index[1] == idx)\n",
    "            neighbors = torch.unique(torch.cat([edge_index[0][mask], edge_index[1][mask]]))\n",
    "            next_frontier.update(neighbors.tolist())\n",
    "        current_frontier = next_frontier - visited\n",
    "        visited.update(current_frontier)\n",
    "\n",
    "    sub_nodes = torch.tensor(sorted(visited), device=edge_index.device)\n",
    "    # Get subgraph edges using PyG utility\n",
    "    sub_edges, _ = subgraph(sub_nodes, edge_index, relabel_nodes=False)\n",
    "\n",
    "    return sub_nodes, sub_edges\n",
    "\n",
    "\n",
    "n_nodes, n_edges = get_node_k_hop_subgraph(data, node_idx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c20c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_labeled_x_features(data: Data, csv_path: str, node_indices: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Displays selected rows from data.x with proper column names from CSV header.\n",
    "\n",
    "    Parameters:\n",
    "    - data (torch_geometric.data.Data): PyG graph object with `x` feature matrix.\n",
    "    - csv_path (str): Path to the CSV file with correct column names.\n",
    "    - node_indices (torch.Tensor): Node indices to extract and display features for.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # Load column names only from CSV\n",
    "    col_names = pd.read_csv(csv_path, nrows=0).columns.tolist()\n",
    "\n",
    "    # Sanity check\n",
    "    assert data.x.size(1) == len(col_names), f\"Feature dim mismatch: data.x has {data.x.size(1)} features, but CSV has {len(col_names)} columns.\"\n",
    "\n",
    "    # Slice features\n",
    "    features = data.x[node_indices].cpu().numpy()\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(features, columns=col_names, index=[f\"Node {i}\" for i in node_indices.tolist()])\n",
    "\n",
    "    # drop columns with all 0s\n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "    # Display the dataframe\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "neighborhood = show_labeled_x_features(data, '../data/graphs/17/node_features.csv', n_nodes)\n",
    "neighborhood.to_latex('../data/graphs/17/neighborhood.tex', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d153649",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pd.read_csv(f'../data/graphs/{graph_num}/node_features.csv').columns.tolist()\n",
    "\n",
    "tick_dict = {i: feature_names[i] for i in range(len(feature_names))}\n",
    "\n",
    "### plot the feature importance\n",
    "node_mask = explanation.node_mask.squeeze()\n",
    "score = node_mask[node_idx].cpu().numpy()\n",
    "import seaborn as sns\n",
    "feat_df = pd.DataFrame({\n",
    "    'Feature': [tick_dict[i] for i in range(len(tick_dict))],\n",
    "    'Importance': score\n",
    "})\n",
    "## drop columns not in neighborhood columns\n",
    "feat_df = feat_df[feat_df['Feature'].isin(neighborhood.columns)]\n",
    "\n",
    "### filter out features with importance less than or equal to 0\n",
    "feat_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.barplot(data=feat_df, x = 'Feature', y='Importance')\n",
    "### add grid lines\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.xticks(ticks=range(len(feat_df)), labels=feat_df['Feature'], rotation=90, ha='right')\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.title(f'Feature Importance for Node {node_idx}')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f22f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_features(data: Data, node_indices: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns feature matrix rows for the given node indices.\n",
    "\n",
    "    Parameters:\n",
    "    - data (torch_geometric.data.Data): PyG graph object\n",
    "    - node_indices (torch.Tensor): Node indices to extract features for\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Features of the selected nodes\n",
    "    \"\"\"\n",
    "    return data.x[node_indices]\n",
    "\n",
    "node_features = get_node_features(data, n_nodes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd9b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "def visualize_edges(edge_index: torch.Tensor, highlight_nodes: torch.Tensor = None, scale_with_size: bool = False):\n",
    "    \"\"\"\n",
    "    Visualizes a simple undirected graph from given edges, without showing node labels.\n",
    "\n",
    "    Parameters:\n",
    "    - edge_index (torch.Tensor): 2 x N tensor of edges\n",
    "    - highlight_nodes (torch.Tensor, optional): Nodes to highlight\n",
    "    - scale_with_size (bool): If True, scales node/font size with graph size\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    edges = edge_index.t().tolist()\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    num_nodes = G.number_of_nodes()\n",
    "\n",
    "    # Dynamic scaling\n",
    "    if scale_with_size:\n",
    "        node_size = max(1000 / (num_nodes**0.5), 100)\n",
    "    else:\n",
    "        node_size = 500\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "    # Draw graph without labels\n",
    "    nx.draw(G, pos, node_color='lightblue', edge_color='gray', node_size=node_size)\n",
    "\n",
    "    if highlight_nodes is not None:\n",
    "        highlight = [int(i) for i in highlight_nodes]\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=highlight, node_color='blue', node_size=node_size)\n",
    "\n",
    "    # plt.title(\"Edge-based Subgraph\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_edges(n_edges, highlight_nodes=n_nodes, scale_with_size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9791fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(data.x, data.edge_index)\n",
    "pred = pred.argmax(dim=1)\n",
    "print(f\"Node {node_idx} prediction: {pred[node_idx].item()}\", flush=True)\n",
    "print(f\"Node {node_idx} true label: {torch.bucketize(data.y[node_idx].item(),bins)}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8593e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "\n",
    "def get_reachable_subgraph(data, edge_index: torch.Tensor, source_idx: int, max_distance: float):\n",
    "    \"\"\"\n",
    "    Traverses the graph from a source node and collects all nodes and edges reachable\n",
    "    within a given cumulative distance (based on feature index 4 in data.x, assumed to be length in meters).\n",
    "\n",
    "    Parameters:\n",
    "    - data (torch_geometric.data.Data): PyG data object with node features\n",
    "    - edge_index (torch.Tensor): 2 x N edge index tensor\n",
    "    - source_idx (int): Starting node index\n",
    "    - max_distance (float): Max cumulative travel distance\n",
    "\n",
    "    Returns:\n",
    "    - reachable_nodes (torch.Tensor): List of reachable node indices\n",
    "    - reachable_edges (torch.Tensor): 2 x M tensor of reachable edges\n",
    "    \"\"\"\n",
    "    # Build adjacency list with lengths as weights\n",
    "    edge_list = edge_index.t().tolist()\n",
    "    lengths = data.x[:, 4]  # feature index 4 is 'length'\n",
    "\n",
    "    graph = {}  # node -> list of (neighbor, edge_idx, length)\n",
    "    for i, (u, v) in enumerate(edge_list):\n",
    "        dist = lengths[u].item()  # assuming length is stored at the source node\n",
    "        graph.setdefault(u, []).append((v, i, dist))\n",
    "        graph.setdefault(v, []).append((u, i, dist))  # undirected\n",
    "\n",
    "    visited = set()\n",
    "    edge_ids = set()\n",
    "    queue = deque([(source_idx, 0)])\n",
    "\n",
    "    while queue:\n",
    "        current_node, total_dist = queue.popleft()\n",
    "        if current_node in visited:\n",
    "            continue\n",
    "        visited.add(current_node)\n",
    "\n",
    "        for neighbor, edge_idx, dist in graph.get(current_node, []):\n",
    "            new_dist = total_dist + dist\n",
    "            if neighbor not in visited and new_dist <= max_distance:\n",
    "                queue.append((neighbor, new_dist))\n",
    "                edge_ids.add(edge_idx)\n",
    "\n",
    "    reachable_nodes = torch.tensor(sorted(visited), device=edge_index.device)\n",
    "    reachable_edges = edge_index[:, list(edge_ids)]\n",
    "\n",
    "    return reachable_nodes, reachable_edges\n",
    "\n",
    "reachable_nodes, reachable_edges = get_reachable_subgraph(data, data.edge_index, node_idx, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_edges(reachable_edges, highlight_nodes=reachable_nodes, scale_with_size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.x[:, 5].cpu().numpy()  # Assuming feature index 5 is 'BC'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "array = x\n",
    "value = number = 1.245451e-07 \n",
    "for i in [1.245451e-07 , 3.09317e-08, 8.9521905e-08, 3.8050902e-07, 1.343647e-07, 2.662745e-07]:\n",
    "    value = i\n",
    "    rank = np.sum(array <= value)  # Number of values ≤ value\n",
    "    quantile = rank / len(array)\n",
    "    print(f\"Value: {value:.8e}, Rank: {rank}, Quantile: {quantile:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
