{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d069375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "from torch_geometric.nn.models import Node2Vec\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "model_name = 'fluent-lake-17'  # Replace with your model name\n",
    "graph_num = 26 \n",
    "weights_prefix = 'best_accuracy'  # Replace with your desired weights prefix\n",
    "random_seed =  100\n",
    "bins = [int(i) for i in \"400 800 1300 2100 3000 3700 4700 7020 9660\".split(' ')] \n",
    "dropout_p =  0.5\n",
    "epochs = 100\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\", flush = True)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\", flush = True)\n",
    "\n",
    "device = 'cpu'\n",
    "bins = torch.tensor(bins, device=device)\n",
    "\n",
    "### load graph data\n",
    "\n",
    "with open(f'../data/graphs/{graph_num}/linegraph_tg.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "def stratified_split(data, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    \"\"\"Splits data into train, validation, and test sets, stratifying by y > 0.\"\"\"\n",
    "\n",
    "    # Create a boolean mask for nodes where y > 0\n",
    "    positive_mask = data.y > 0\n",
    "    print(f\"Positive nodes: {positive_mask.sum().item()}, Total nodes: {data.num_nodes}\", flush = True)\n",
    "\n",
    "    # Get indices of positive and negative nodes\n",
    "    positive_indices = positive_mask.nonzero(as_tuple=False).squeeze()\n",
    "    negative_indices = (~positive_mask).nonzero(as_tuple=False).squeeze()\n",
    "\n",
    "    # Split positive indices\n",
    "    pos_train_idx, pos_temp_idx = train_test_split(positive_indices, train_size=train_ratio, random_state=random_seed)  # Adjust random_state for consistent splits\n",
    "    pos_val_idx, pos_test_idx = train_test_split(pos_temp_idx, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=random_seed)\n",
    "\n",
    "    # Split negative indices\n",
    "    neg_train_idx, neg_temp_idx = train_test_split(negative_indices, train_size=train_ratio, random_state=random_seed)\n",
    "    neg_val_idx, neg_test_idx = train_test_split(neg_temp_idx, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=random_seed)\n",
    "\n",
    "    # Combine indices\n",
    "    train_idx = torch.cat([pos_train_idx, neg_train_idx])\n",
    "    val_idx = torch.cat([pos_val_idx, neg_val_idx])\n",
    "    test_idx = torch.cat([pos_test_idx, neg_test_idx])\n",
    "\n",
    "    # Create masks\n",
    "    train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "    train_mask[train_idx] = True\n",
    "    val_mask[val_idx] = True\n",
    "    test_mask[test_idx] = True\n",
    "\n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    ## print number of nodes in each set with y > 0\n",
    "    print(f\"Train nodes with y > 0: {(data.y[data.train_mask] > 0.0).sum()}\", flush = True)\n",
    "    print(f\"Validation nodes with y > 0: {(data.y[data.val_mask] > 0.0).sum()}\", flush = True)\n",
    "    print(f\"Test nodes with y > 0: {(data.y[data.test_mask] > 0.0).sum()}\", flush = True)\n",
    "    return data\n",
    "\n",
    "# remove fist feature of x\n",
    "# data.x = data.x[:, 1:]\n",
    "\n",
    "data.edge_index = data.edge_index.contiguous()\n",
    "data.x = data.x.contiguous()\n",
    "data.y = data.y.contiguous()\n",
    "\n",
    "print(data.x.shape, data.edge_index.shape, data.y.shape, flush = True)\n",
    "\n",
    "data = stratified_split(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c712f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/graphs/{graph_num}/linegraph_nx.pkl', 'rb') as f:\n",
    "    H = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724174f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a MultiDiGraph with multiple edges between nodes\n",
    "MDG = nx.MultiDiGraph()\n",
    "MDG.add_edge(1, 2, key='a', weight=3)\n",
    "MDG.add_edge(1, 2, key='b', weight=7)\n",
    "MDG.add_edge(2, 3, weight=5)\n",
    "\n",
    "# Convert to Graph\n",
    "G = nx.Graph(MDG)\n",
    "print(G.edges(data=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e56769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Definitions ---\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_layers):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "        self.input_layer = GCNConv(data.num_features, hidden_channels, improved=True, cached=True)\n",
    "\n",
    "        # Create intermediate hidden layers (optional)\n",
    "        self.hidden_layers = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.hidden_layers.append(GCNConv(hidden_channels, hidden_channels, improved=True, cached=True))\n",
    "\n",
    "        self.output_layer = GCNConv(hidden_channels, len(bins) + 1, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.input_layer(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=dropout_p, training=self.training)\n",
    "\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=dropout_p, training=self.training)\n",
    "\n",
    "        x = self.output_layer(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels, num_layers, num_heads):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(42)  # Replace with your desired seed\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        # Input layer\n",
    "        self.convs.append(GATConv(data.num_features, hidden_channels, heads=num_heads, concat=True))\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers):\n",
    "            self.convs.append(GATConv(hidden_channels * num_heads, hidden_channels, heads=num_heads, concat=True))\n",
    "\n",
    "        # Output layer\n",
    "        self.convs.append(GATConv(hidden_channels * num_heads, len(bins) + 1, heads=1, concat=False))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p=0.5, training=self.training)  # Adjust dropout probability as needed\n",
    "\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = f'../data/graphs/{graph_num}/models/{model_name}_{weights_prefix}.pt'\n",
    "\n",
    "model = torch.load(f'../data/graphs/{graph_num}/models/{model_name}.pt', map_location=device)\n",
    "### load weights onto model\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdae08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds  = model(data.x.to(device), data.edge_index.to(device))\n",
    "# assign predicted aadt bin to test nodes\n",
    "preds = preds.argmax(dim=1)\n",
    "\n",
    "for node, pred in zip(list(H.nodes()), preds):\n",
    "    H.nodes[node]['pred'] = pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get node with  highest aadt in H\n",
    "highest_idx = np.argmax(data.y)\n",
    "highest_node = list(H.nodes(data=True))[highest_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "g = data.old_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = nx.single_source_dijkstra_path_length(H, highest_node[0], cutoff=2000, weight='weight')\n",
    "### create subgraph with all nodes within 1000m of highest node\n",
    "subgraph_nodes = list(lengths.keys())\n",
    "subgraph_edges = [(u, v) for u, v in H.edges() if u in subgraph_nodes and v in subgraph_nodes]\n",
    "subgraph = H.edge_subgraph(subgraph_edges)\n",
    "subgraph = subgraph.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcacf4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_preds = {}\n",
    "node_aadt = {}\n",
    "node_ebc = {}\n",
    "for node in H.nodes(data=True):\n",
    "    node_preds[node[0]] = node[1]['pred']\n",
    "    node_aadt[node[0]] = node[1]['aadt']\n",
    "    node_ebc[node[0]] = node[1]['bc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d2a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_preds = {}\n",
    "edge_aadt = {}\n",
    "edge_ebc = {}\n",
    "for u, v, k in g.edges(keys=True):\n",
    "    if (u, v) in node_preds:\n",
    "        edge_preds[(u, v, k)] = node_preds[(u, v)]\n",
    "    if (u, v) in node_aadt:\n",
    "        edge_aadt[(u, v, k)] = node_aadt[(u, v)]\n",
    "    if (u, v) in node_ebc:\n",
    "        edge_ebc[(u, v, k)] = node_ebc[(u, v)]\n",
    "\n",
    "\n",
    "nx.set_edge_attributes(g, edge_preds, name='pred')\n",
    "nx.set_edge_attributes(g, edge_aadt, name='aadt')\n",
    "nx.set_edge_attributes(g, edge_ebc, name='ebc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove edges from g that are not in subgraph_edges\n",
    "edges_to_remove = []\n",
    "for edge in g.edges():\n",
    "    if edge not in subgraph_nodes:\n",
    "        edges_to_remove.append(edge)\n",
    "\n",
    "\n",
    "for edge in edges_to_remove:\n",
    "    g.remove_edge(edge[0], edge[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8a7bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import momepy as mp \n",
    "gdf = mp.nx_to_gdf(g)\n",
    "# nx.draw(subgraph, with_labels=False)\n",
    "gdf[1].plot(column='pred', cmap='turbo', legend=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c30d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import momepy as mp \n",
    "gdf = mp.nx_to_gdf(g)\n",
    "# nx.draw(subgraph, with_labels=False)\n",
    "gdf[1].query('aadt > 0').plot(column='aadt', cmap='turbo', legend=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_edge_gdf_columns(gdf, columns=['pred', 'ebc', 'aadt'], cmap='viridis', k=10):\n",
    "    \"\"\"\n",
    "    Plots multiple edge attributes from a GeoDataFrame using geopandas plot.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf: GeoDataFrame containing LineString geometries and attribute columns\n",
    "    - columns: list of attribute names to plot\n",
    "    - cmap: colormap to use\n",
    "    \"\"\"\n",
    "    n = len(columns)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(5 * n, 5))\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]  # Ensure axes is always iterable\n",
    "\n",
    "    for col, ax in zip(columns, axes):\n",
    "        gdf.plot(column=col, cmap=cmap, legend=True, ax=ax, linewidth=2, k = k)\n",
    "        ax.set_title(f\"{col} values\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e802f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b962ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# aadt_tensor = torch.tensor(gdf[1]['aadt'].values)\n",
    "# bins_tensor = torch.tensor(bins)\n",
    "\n",
    "# gdf[1]['binned_aadt'] = torch.bucketize(aadt_tensor, bins_tensor, right=False).numpy() - 1\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Bucketize\n",
    "aadt_tensor = torch.tensor(gdf[1]['aadt'].values)\n",
    "bins_tensor = torch.tensor(bins)\n",
    "\n",
    "# right=False matches pd.cut(left-inclusive, right-exclusive)\n",
    "bucket_indices = torch.bucketize(aadt_tensor, bins_tensor, right=False).numpy()\n",
    "\n",
    "# Clamp to 0â€“9\n",
    "bucket_indices = np.clip(bucket_indices - 1, 0, len(bins) - 2)  # gives labels 0â€“9\n",
    "\n",
    "# Assign\n",
    "gdf[1]['binned_aadt'] = bucket_indices\n",
    "\n",
    "\n",
    "\n",
    "gdf[1]['pred_diff'] = gdf[1]['pred'] - gdf[1]['binned_aadt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc04f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_bin_cutoff_diff(row, bins_array):\n",
    "    pred_idx = row['pred']\n",
    "    true_idx = row['binned_aadt']\n",
    "\n",
    "    if pd.isna(pred_idx) or pd.isna(true_idx):\n",
    "        return float('nan')\n",
    "\n",
    "    i = int(pred_idx)\n",
    "    j = int(true_idx)\n",
    "\n",
    "    lower_bin = min(i, j)\n",
    "    upper_bin = max(i, j)\n",
    "\n",
    "    # Clamp upper_bin + 1 to len(bins_array) - 1\n",
    "    upper_cutoff_idx = min(upper_bin + 1, len(bins_array) - 1)\n",
    "\n",
    "    lower_cutoff = bins_array[lower_bin]\n",
    "    upper_cutoff = bins_array[upper_cutoff_idx]\n",
    "\n",
    "    return abs(upper_cutoff - lower_cutoff)\n",
    "\n",
    "# Apply safely\n",
    "bins_array = list(bins)\n",
    "gdf[1]['aadt_diff_est'] = gdf[1].apply(lambda row: max_bin_cutoff_diff(row, bins_array), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d258c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_edge_gdf_columns(gdf[1].query('aadt > 0'), columns=['pred', 'binned_aadt'], cmap= 'turbo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee60006",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[1].query('aadt > 0').explore(\n",
    "    column='binned_aadt',\n",
    "    cmap='RdBu',\n",
    "    legend=True,\n",
    "    tooltip=['pred', 'ebc', 'aadt', 'binned_aadt', 'pred_diff', 'name', 'aadt_diff_est', 'highway'],\n",
    "    name='Predicted AADT',\n",
    "    style_kwds={\n",
    "        'fillOpacity': 0.7,\n",
    "        'weight': 5\n",
    "    },\n",
    "    # tiles='Esri.WorldImagery',  #Satellite background\n",
    "    tiles='cartodb positron',\n",
    "    # vmin=-max_abs,\n",
    "    # vmax= max_abs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c32a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[1].query('aadt > 0').explore(\n",
    "    column='pred',\n",
    "    cmap='RdBu',\n",
    "    legend=True,\n",
    "    tooltip=['pred', 'ebc', 'aadt', 'binned_aadt', 'pred_diff', 'name', 'aadt_diff_est', 'highway'],\n",
    "    name='Predicted AADT',\n",
    "    style_kwds={\n",
    "        'fillOpacity': 0.7,\n",
    "        'weight': 5  # ðŸ”¥ Thicker lines\n",
    "    },\n",
    "    # tiles='Esri.WorldImagery',  #Satellite background\n",
    "    tiles='cartodb positron',\n",
    "    # vmin=-max_abs,\n",
    "    # vmax= max_abs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc25fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[1].query('aadt > 0').plot(column='pred_diff', cmap='turbo', legend=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da824c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import GNNExplainer, Explainer\n",
    "\n",
    "# Move data to device\n",
    "x = data.x.to(device)\n",
    "edge_index = data.edge_index.to(device)\n",
    "\n",
    "# Create explainer\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=5),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type=None,  # No edge mask in this case\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Run explanation for a single node\n",
    "explanation = explainer(x=x, edge_index=edge_index, index=highest_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace plot y values with feature names\n",
    "import matplotlib.pyplot as plt\n",
    "features = pd.read_csv(f'../data/graphs/{graph_num}/node_features.csv').columns[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c37042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# center_node is an edge from g (since H is the line graph of g)\n",
    "center_edge = list(H.nodes())[highest_idx]\n",
    "\n",
    "# Get neighboring edges in H (i.e., edges in g that share a node with center_edge)\n",
    "neighbor_edges = list(H.neighbors(center_edge))\n",
    "neighbor_edges.append(center_edge)  # Include the center edge itself\n",
    "\n",
    "h_subgraph = H.subgraph(neighbor_edges)\n",
    "\n",
    "new_g = nx.Graph()\n",
    "for u, v in h_subgraph.nodes():\n",
    "    new_g.add_edge(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7bc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_labels = {}\n",
    "for s, t in new_g.edges():\n",
    "    for i in g.edges((s, t), data=True):\n",
    "        if 'name' in i[2]:\n",
    "            edge_labels[(s, t)] = i[2]['name']\n",
    "            print(s, t, i[2]['name'])\n",
    "            ### copy all attributes from g to new_g\n",
    "            nx.set_edge_attributes(new_g, {(s, t) : i[2]})\n",
    "            break\n",
    "        else:\n",
    "            print('NO NAME')\n",
    "    nx.set_node_attributes(new_g, {s: g.nodes[s]})\n",
    "    nx.set_node_attributes(new_g, {t: g.nodes[t]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49148981",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_g.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sub = mp.nx_to_gdf(new_g, lines = True, points=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(new_g.edges()) == sorted(edge_labels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74395f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_g.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(new_g)\n",
    "plt.figure(figsize=(7, 7))\n",
    "nx.draw(new_g, with_labels=True, pos=pos)\n",
    "nx.draw_networkx_edge_labels(new_g, edge_labels=edge_labels, pos=pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'amenity shop building aerialway aeroway barrier boundary craft emergency highway historic landuse leisure healthcare military natural office power public_transport railway place service tourism waterway route water'\n",
    "b = 'aerialway aeroway amenity barrier boundary building craft emergency healthcare highway historic landuse leisure man_made military natural office place power public_transport railway route shop telecom tourism water waterway'\n",
    "\n",
    "# print element in b not in a\n",
    "for i in b.split(' '):\n",
    "    if i not in a.split(' '):\n",
    "        print(i)\n",
    "\n",
    "# print element in a not in b\n",
    "for i in a.split(' '):\n",
    "    if i not in b.split(' '):\n",
    "      print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044aac57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
