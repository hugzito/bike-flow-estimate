{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3526c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "\n",
    "import os, torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "from torch_geometric.nn.models import Node2Vec\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "GCNConv._orig_propagate = GCNConv.propagate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.explain import GNNExplainer, Explainer\n",
    "from models import *\n",
    "from tg_functions import *\n",
    "from bike_functions import *\n",
    "\n",
    "dropout_p = 0.5\n",
    "use_gat = True\n",
    "bins = [int(i) for i in os.getenv(\"BINS\", \"400 800 1300 2100 3000 3700 4700 7020 9660\").split(' ')]\n",
    "bins = [int(i) for i in os.getenv(\"BINS\", \"3000\").split(' ')]\n",
    "\n",
    "bins = torch.tensor(bins, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "hidden_c = 100\n",
    "num_layers = 0\n",
    "random_seed = 100\n",
    "nh = 1\n",
    "\n",
    "graph_num = 29  # Replace with your graph number\n",
    "model_name = 'upbeat-firebrand-246' # Replace with your model name\n",
    "weight_prefix = 'best_accuracy'  # Replace with your weight prefix\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\", flush = True)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\", flush = True)\n",
    "\n",
    "# device = 'cpu'\n",
    "\n",
    "with open(f'../data/graphs/{graph_num}/linegraph_tg.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data.edge_index = data.edge_index.contiguous()\n",
    "data.x = data.x.contiguous()\n",
    "data.y = data.y.contiguous()\n",
    "\n",
    "data = stratified_split(data = data , random_seed = random_seed)\n",
    "\n",
    "# --- Model Instantiation ---\n",
    "model = GAT(hidden_c, num_layers, random_seed, bins, data, nh).to(device) if use_gat else GCN(hidden_c, num_layers, random_seed, bins, data).to(device)\n",
    "\n",
    "if use_gat == 'MLP':\n",
    "    model = MLP(hidden_c, num_layers, random_seed, bins, data, nh).to(device)\n",
    "\n",
    "# Load the model with the GCN class\n",
    "model = torch.load(f'../data/graphs/{graph_num}/models/{model_name}.pt', map_location=device)\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(f'../data/graphs/{graph_num}/models/{model_name}_{weight_prefix}.pt', map_location=device))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "data.edge_index = data.edge_index.contiguous()\n",
    "data.x = data.x.contiguous()\n",
    "data.y = data.y.contiguous()\n",
    "print(data.x.shape, data.edge_index.shape, data.y.shape, flush = True)\n",
    "data = stratified_split(data, random_seed=random_seed)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch_geometric.explain import Explanation\n",
    "\n",
    "def load_explanation_from_json(json_path, device='cpu'):\n",
    "    \"\"\"\n",
    "    Loads an explanation from a JSON file and converts lists to torch tensors where appropriate.\n",
    "    \n",
    "    Parameters:\n",
    "    - json_path: Path to the explanation JSON file.\n",
    "    - device: The device to place tensors on ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "    - explanation: An Explanation object.\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        explanation_dict = json.load(f)\n",
    "    \n",
    "    # Recursively convert lists to torch tensors\n",
    "    def convert(item):\n",
    "        if isinstance(item, list):\n",
    "            # If it's a nested list (likely a tensor)\n",
    "            if item and isinstance(item[0], list):\n",
    "                return torch.tensor(item, device=device)\n",
    "            # Otherwise, could be a 1D list\n",
    "            else:\n",
    "                return torch.tensor(item, device=device)\n",
    "        elif isinstance(item, dict):\n",
    "            return {k: convert(v) for k, v in item.items()}\n",
    "        else:\n",
    "            return item\n",
    "\n",
    "    explanation_converted = {k: convert(v) for k, v in explanation_dict.items()}\n",
    "    explanation = Explanation(**explanation_converted)\n",
    "    return explanation\n",
    "\n",
    "json_path = f'../data/graphs/{graph_num}/explanations/{model_name}/graph_level_explanation.json'\n",
    "explanation = load_explanation_from_json(json_path, device=device)\n",
    "print(\"âœ… Explanation loaded and moved to device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get 20 most important features\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "\n",
    "# scores = explanation.node_mask.sum(dim=0)\n",
    "# scores = pd.DataFrame(scores.cpu().numpy(), index=data.feat_names, columns=['importance'])\n",
    "# scores = scores.sort_values(by='importance', ascending=False).head(20)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# sns.barplot(y=scores.index, x=scores['importance'])\n",
    "# plt.title('Top 20 Important Features')\n",
    "# plt.xlabel('Importance Score')\n",
    "# plt.ylabel('Features')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# import pandas as pd\n",
    "# per_bin_gradients = pd.read_csv(f'../data/graphs/{graph_num}/explanations/{model_name}/per_bin_gradients_all_nodes.csv')\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# sns.heatmap(per_bin_gradients.groupby('bin_index').mean().drop(columns=['node_index'])[scores.index].T, annot=True, cmap='coolwarm', cbar_kws={'label': 'Gradient'}, vmin=-0.1, vmax=0.1)\n",
    "# plt.title('Average Gradient per Bin for Top 20 Features')\n",
    "# plt.xlabel('Bin Index')\n",
    "# plt.ylabel('Features')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93884d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Top 20 Important Features (from explanation) ===\n",
    "scores = explanation.node_mask.sum(dim=0)\n",
    "scores = pd.DataFrame(scores.cpu().numpy(), index=data.feat_names, columns=['importance'])\n",
    "scores = scores.sort_values(by='importance', ascending=False).head(20)\n",
    "\n",
    "# === Per-Bin Gradients (load CSV) ===\n",
    "per_bin_gradients = pd.read_csv(f'../data/graphs/{graph_num}/explanations/{model_name}/per_bin_gradients_all_nodes.csv')\n",
    "gradients_mean = per_bin_gradients.groupby('bin_index').mean().drop(columns=['node_index'])[scores.index]\n",
    "\n",
    "# === Plot ===\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 8))\n",
    "\n",
    "# Plot 1: Bar Plot of Top 20 Important Features\n",
    "sns.barplot(y=scores.index, x=scores['importance'], ax=axes[0])\n",
    "axes[0].set_title('Top 20 Important Features')\n",
    "axes[0].set_xlabel('Importance Score')\n",
    "axes[0].set_ylabel('Features')\n",
    "\n",
    "# Plot 2: Heatmap of Average Gradient per Bin\n",
    "sns.heatmap(\n",
    "    gradients_mean.T,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    cbar_kws={'label': 'Gradient'},\n",
    "    vmin=-0.1,\n",
    "    vmax=0.1,\n",
    "    ax=axes[1],\n",
    "    fmt=\".2f\"\n",
    ")\n",
    "axes[1].set_title('Average Gradient per Bin for Top 20 Features')\n",
    "axes[1].set_xlabel('Bin Index')\n",
    "axes[1].set_ylabel('Features')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a196ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the spearman correlation between features and values\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearmans = []\n",
    "mask = data.y > 0\n",
    "\n",
    "for feat in data.feat_names:\n",
    "    feat_index = data.feat_names.index(feat)\n",
    "    feat_values = data.x[mask, feat_index].cpu().numpy()\n",
    "    target_values = data.y[mask].cpu().numpy()\n",
    "    \n",
    "    if len(feat_values) > 1 and len(target_values) > 1:\n",
    "        corr, _ = spearmanr(feat_values, target_values)\n",
    "        spearmans.append((feat, corr))\n",
    "\n",
    "spearman_df = pd.DataFrame(spearmans, columns=['Feature', 'Spearman Correlation'])\n",
    "\n",
    "# filter to top and bottom 10 features\n",
    "top_bottom = pd.concat([\n",
    "    spearman_df.nlargest(10, 'Spearman Correlation'),\n",
    "    spearman_df.nsmallest(10, 'Spearman Correlation')\n",
    "]).sort_values(by='Spearman Correlation', ascending=False)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x='Spearman Correlation', y='Feature', data=top_bottom)\n",
    "plt.title('Top and Bottom 10 Features by Spearman Correlation')\n",
    "plt.xlabel('Spearman Correlation')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91393d12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
