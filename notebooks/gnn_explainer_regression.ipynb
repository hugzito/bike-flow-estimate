{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ae71bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device: NVIDIA GeForce RTX 2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_33936\\1491516534.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'../data/graphs/{graph_num}/models/{model_name}.pt', map_location=device)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_33936\\1491516534.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'../data/graphs/{graph_num}/models/{model_name}_{weight_prefix}.pt', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (convs): ModuleList(\n",
       "    (0): GATConv(32, 300, heads=1)\n",
       "    (1): GATConv(300, 1, heads=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "\n",
    "import os, torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "from torch_geometric.nn.models import Node2Vec\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "GCNConv._orig_propagate = GCNConv.propagate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.explain import GNNExplainer, Explainer\n",
    "from models import *\n",
    "from tg_functions import *\n",
    "from bike_functions import *\n",
    "\n",
    "dropout_p = 0.5\n",
    "use_gat = True\n",
    "bins = [int(i) for i in os.getenv(\"BINS\", \"400 800 1300 2100 3000 3700 4700 7020 9660\").split(' ')]\n",
    "bins = torch.tensor(bins, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bins = 'regression'\n",
    "hidden_c = 300\n",
    "num_layers = 0\n",
    "random_seed = 100\n",
    "nh = 1\n",
    "\n",
    "\n",
    "graph_num = 29  # Replace with your graph number\n",
    "\n",
    "model_name = 'test_run' # Replace with your model name\n",
    "\n",
    "weight_prefix = 'best_accuracy'  # Replace with your weight prefix\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\", flush = True)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\", flush = True)\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "with open(f'../data/graphs/{graph_num}/linegraph_tg.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data.edge_index = data.edge_index.contiguous()\n",
    "data.x = data.x.contiguous()\n",
    "data.y = data.y.contiguous()\n",
    "\n",
    "# --- Model Instantiation ---\n",
    "model = GAT(hidden_c, num_layers, random_seed, bins, data, nh).to(device) if use_gat else GCN(hidden_c, num_layers, random_seed, bins, data).to(device)\n",
    "\n",
    "if use_gat == 'MLP':\n",
    "    model = MLP(hidden_c, num_layers, random_seed, bins, data, nh).to(device)\n",
    "\n",
    "# Load the model with the GCN class\n",
    "model = torch.load(f'../data/graphs/{graph_num}/models/{model_name}.pt', map_location=device)\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(f'../data/graphs/{graph_num}/models/{model_name}_{weight_prefix}.pt', map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f1d465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([144282, 32]) torch.Size([2, 393834]) torch.Size([144282])\n"
     ]
    }
   ],
   "source": [
    "data.edge_index = data.edge_index.contiguous()\n",
    "data.x = data.x.contiguous()\n",
    "data.y = data.y.contiguous()\n",
    "print(data.x.shape, data.edge_index.shape, data.y.shape, flush = True)\n",
    "data = stratified_split(data)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc6c5055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import GNNExplainer, Explainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=1),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type=None,\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='node',\n",
    "    ),\n",
    ")\n",
    "pred = model(data.x.to(device), data.edge_index.to(device))\n",
    "# pred = out.argmax(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1913fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data.val_mask.squeeze() & (data.y > 0).squeeze()\n",
    "node_idx = torch.nonzero(mask, as_tuple=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ac8f5df",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m data_x\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m node_idx:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# 1. Explain the node\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     explanation \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     node_mask \u001b[38;5;241m=\u001b[39m explanation\u001b[38;5;241m.\u001b[39mnode_mask\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# 2. Prediction and true label\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\envs\\pygenv\\Lib\\site-packages\\torch_geometric\\explain\\explainer.py:196\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[1;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should not be provided for the explanation \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplanation_type\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 196\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_target(prediction)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\envs\\pygenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\envs\\pygenv\\Lib\\site-packages\\torch_geometric\\explain\\explainer.py:115\u001b[0m, in \u001b[0;36mExplainer.get_prediction\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 115\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(training)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\envs\\pygenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\envs\\pygenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\chris\\Documents\\thesis\\new_thesis_dir\\bike-flow-estimate\\notebooks\\../scripts\\models.py:55\u001b[0m, in \u001b[0;36mGAT.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m---> 55\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(x)\n\u001b[0;32m     57\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)  \u001b[38;5;66;03m# Adjust dropout probability as needed\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\envs\\pygenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\envs\\pygenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\envs\\pygenv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:335\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    331\u001b[0m x \u001b[38;5;241m=\u001b[39m (x_src, x_dst)\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# Next, we compute node-level attention coefficients, both for source\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# and target nodes (if present):\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m alpha_src \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mx_src\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matt_src\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m alpha_dst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x_dst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (x_dst \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_dst)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    337\u001b[0m alpha \u001b[38;5;241m=\u001b[39m (alpha_src, alpha_dst)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Assume 'graph_num', 'node_idx', 'data', 'model', 'explainer' already exist\n",
    "\n",
    "# Load feature names\n",
    "feats_df = pd.read_csv(f'../data/graphs/{graph_num}/node_features.csv')\n",
    "if 'aadt' in feats_df.columns:\n",
    "    feats_df = feats_df.drop(columns=['aadt'])\n",
    "if 'osmid' in feats_df.columns:\n",
    "    feats_df = feats_df.drop(columns=['osmid'])\n",
    "\n",
    "\n",
    "# Your secondary to primary mapping\n",
    "secondary_to_primary = {\n",
    "    # [your dictionary here]\n",
    "}\n",
    "\n",
    "# Initialize storage\n",
    "scores = {}       # Collect importance scores\n",
    "gradients = {}    # Collect target class gradients\n",
    "\n",
    "data_x = data.x.to(device)\n",
    "edge_index = data.edge_index.to(device)\n",
    "data_y = data.y.to(device)\n",
    "\n",
    "data_x.requires_grad_(True)\n",
    "\n",
    "for idx in node_idx:\n",
    "    # 1. Explain the node\n",
    "    explanation = explainer(data_x, edge_index, index=idx)\n",
    "    node_mask = explanation.node_mask.squeeze()\n",
    "\n",
    "    # 2. Prediction and true label\n",
    "    curr_pred = pred[idx].item()\n",
    "    target = data_y[idx].item()\n",
    "\n",
    "    # 3. Importance scores (all features)\n",
    "    score = node_mask.sum(dim=0).detach().cpu().numpy().flatten()\n",
    "\n",
    "    # 4. Gradients\n",
    "    data_x.grad = None\n",
    "    pred = model(data_x, edge_index)\n",
    "    pred[idx].backward()\n",
    "\n",
    "    gradients[idx] = data_x.grad[idx].cpu().numpy().flatten()\n",
    "    scores[idx] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Get the feature names\n",
    "feats = feats_df.columns.to_numpy()\n",
    "\n",
    "# 6. Create a DataFrame for the scores\n",
    "scores_df = pd.DataFrame(scores).T\n",
    "scores_df.columns = feats\n",
    "# 7. Create a DataFrame for the gradients\n",
    "\n",
    "gradients_df = pd.DataFrame(gradients).T\n",
    "gradients_df.columns = feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0140aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(scores_df)\n",
    "display(gradients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0678d8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
