{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline GCN testing\n",
    "Notebook to create and evaluate GCN against EBC on predicting number of passing bicyclists in *copenhagen?*\n",
    "- Preprocess EBC for graph DONE\n",
    "- Assign Metrics from data\n",
    "- Create Torch Graph\n",
    "- Evaluate against SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric as tg\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import shapely\n",
    "import momepy as mp \n",
    "import esda\n",
    "import seaborn as sns\n",
    "from shapely.strtree import STRtree\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, glob\n",
    "\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = 55.6867243, 12.5700724\n",
    "dist = 10000\n",
    "features = ['amenity',\n",
    "            'shop',\n",
    "            'building',\n",
    "            'aerialway',\n",
    "            'aeroway', \n",
    "            'barrier', \n",
    "            'boundary', \n",
    "            'craft', \n",
    "            'emergency', \n",
    "            'highway', \n",
    "            'historic',\n",
    "            'landuse', \n",
    "            'leisure', \n",
    "            'healthcare', \n",
    "            'military',\n",
    "            'natural',\n",
    "            'office',\n",
    "            'power',\n",
    "            'public_transport',\n",
    "            'railway',\n",
    "            'place',\n",
    "            'service', \n",
    "            'tourism', \n",
    "            'waterway', \n",
    "            'route', \n",
    "            'water'\n",
    "]\n",
    "expand_features = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ['shop', 'route', 'highway', 'waterway', 'width', 'length', 'aerialway', 'power', 'healthcare']:\n",
    "\tif item in features:\n",
    "\t\tfeatures.remove(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_graph(lat, lon, dist, features, expand_features):\n",
    "    g = ox.graph_from_point((lat, lon), dist=dist, network_type='bike', simplify=True, retain_all=False)\n",
    "    feat_dict = {i : True for i in features}\n",
    "    amenities = ox.features.features_from_point((lat, lon), tags=feat_dict, dist=dist)\n",
    "    amenities = amenities[amenities.geometry.notnull()]\n",
    "    amenities['new_col'] = np.nan\n",
    "\n",
    "    for feat in features:\n",
    "        if feat not in expand_features:\n",
    "            amenities.loc[amenities[feat].notnull(), 'new_col'] = feat\n",
    "    \n",
    "    amenities['amenity'] = amenities['new_col']\n",
    "\n",
    "    for feat in expand_features:\n",
    "        amenities['amenity'].fillna(amenities[feat], inplace=True)\n",
    "    amenities = amenities[amenities['amenity'].notnull()]\n",
    "\n",
    "    gdf = mp.nx_to_gdf(g, points=False, lines=True, spatial_weights=True).to_crs(epsg=3857)\n",
    "    gdf = gdf[gdf.geometry.notnull()].reset_index(drop=True)\n",
    "    return g, gdf, amenities\n",
    "\n",
    "g, gdf, amenities = get_city_graph(lat,\n",
    "                                    lon,\n",
    "                                    dist,\n",
    "                                    features = features, \n",
    "                                    expand_features = expand_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### carry weights over to line graph\n",
    "\n",
    "def create_linegraph(g):\n",
    "    g = nx.Graph(g)\n",
    "    H = nx.line_graph(g)\n",
    "    H.add_nodes_from((node, g.edges[node]) for node in H)   \n",
    "    for s, t in H.edges:\n",
    "        H.edges[(s, t)]['weight'] = g.edges[s]['length'] + g.edges[t]['length']\n",
    "    return H\n",
    "\n",
    "H = create_linegraph(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_bc(shortest_paths, graph):\n",
    "    bc = {i: 0 for i in graph.nodes}\n",
    "    for node in tqdm(graph.nodes):\n",
    "        for path in shortest_paths[node].values():\n",
    "            for node_visited in set(path):\n",
    "                bc[node_visited] += 1\n",
    "    total_nodes = graph.number_of_nodes() ** 2\n",
    "    return {node: count / total_nodes for node, count in bc.items()}\n",
    "\n",
    "ebc = dict(nx.all_pairs_dijkstra_path(H,\n",
    "                                    weight='weight',\n",
    "                                    cutoff=1000,\n",
    "))\n",
    "bc = calc_bc(ebc, H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc2 = {}\n",
    "for x, y in bc:\n",
    "    bc2[(x, y)] = bc[(x, y)]\n",
    "\n",
    "nx.set_node_attributes(H, bc2, 'bc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges = mp.nx_to_gdf(g)\n",
    "filepath = '../data/raw/trafiktaelling.json'\n",
    "gdf2 = gpd.GeoDataFrame.from_file(filepath)\n",
    "gdf2.set_crs(epsg=4326, inplace=True)\n",
    "gdf2 = gdf2.to_crs(epsg=3857)\n",
    "gdf2['geometry'] = gdf2['geometry']\n",
    "# gdf2 = gdf2[gdf2['geometry'].within(gdf['geometry'])]\n",
    "### export only relevant columns\n",
    "gdf_new = gdf2[['id', 'vejnavn', 'geometry', 'aadt_cykler']]\n",
    "### remove null values on aadt_cykler\n",
    "gdf_new = gdf_new[gdf_new['aadt_cykler'].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "gdf_new = gdf_new.cx[xmin:xmax, ymin:ymax]\n",
    "gdf_new.to_crs(epsg=4326, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestrings = [i[2]['geometry'] if 'geometry' in i[2] else None for i in list(g.edges(data=True))]\n",
    "from_node = [i[0] for i in list(g.edges(data=True))]\n",
    "to_node = [i[1] for i in list(g.edges(data=True))]\n",
    "\n",
    "tree = STRtree(linestrings)\n",
    "for i, row in tqdm(gdf_new.iterrows(), total=len(gdf_new)):\n",
    "    point = row['geometry']\n",
    "    if point is None:\n",
    "        continue\n",
    "    nearest_edge_idx = tree.nearest(point)\n",
    "    nearest_edge = linestrings[nearest_edge_idx]\n",
    "    nearest_edge_distance = nearest_edge.distance(point)\n",
    "    start_node = from_node[linestrings.index(nearest_edge)]\n",
    "    end_node = to_node[linestrings.index(nearest_edge)]\n",
    "    \n",
    "    # Ensure the edge exists in the graph\n",
    "    if (start_node, end_node) not in H.nodes():\n",
    "        if (end_node, start_node) not in H.nodes:\n",
    "            continue\n",
    "        else:\n",
    "            start_node, end_node = end_node, start_node\n",
    "\n",
    "    if 'aadt' not in H.nodes()[(start_node, end_node)]:\n",
    "        H.nodes()[(start_node, end_node)]['aadt'] = row['aadt_cykler']\n",
    "        H.nodes()[(start_node, end_node)]['aadt_distance'] = nearest_edge_distance\n",
    "    if 'aadt_distance' not in H.nodes()[(start_node, end_node)] or H.nodes()[(start_node, end_node)]['aadt_distance'] > nearest_edge_distance:\n",
    "        H.nodes()[(start_node, end_node)]['aadt'] = row['aadt_cykler']\n",
    "        H.nodes()[(start_node, end_node)]['aadt_distance'] = nearest_edge_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node, value in H.nodes(data=True):\n",
    "    if 'aadt' not in value.keys():\n",
    "        value['aadt'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amenities = amenities.reset_index()\n",
    "nodes = list((node, linestring) for node, linestring in H.nodes(data='geometry'))\n",
    "nodes = [node for node in nodes if node[1] is not None]\n",
    "linestrings = [linestring for node, linestring in nodes]\n",
    "nodes = [node for node, linestring in nodes]\n",
    "assert len(nodes) == len(linestrings)\n",
    "amenities['geometry'] = amenities['geometry'].apply(lambda x: x.centroid if x.geom_type == 'Polygon' else x)\n",
    "tree = STRtree(linestrings)\n",
    "for geom, amenity in zip(amenities['geometry'], amenities['amenity']):\n",
    "    nearest = tree.nearest(geom)\n",
    "    nearest = nodes[nearest]\n",
    "    if 'amenity' not in H.nodes[nearest]:\n",
    "        H.nodes[nearest]['amenity'] = [amenity]\n",
    "    else:\n",
    "        H.nodes[nearest]['amenity'].append(amenity)\n",
    "\n",
    "from collections import Counter\n",
    "for i in H.nodes(data=True):\n",
    "    if 'amenity' in i[1]:\n",
    "        amenity_counts = Counter(i[1]['amenity'])\n",
    "        for key in amenity_counts:\n",
    "            H.nodes[i[0]][key] = amenity_counts[key]\n",
    "        ## drop the amenity key\n",
    "        H.nodes[i[0]].pop('amenity', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in H.nodes(data=True):\n",
    "    node[1].pop('geometry', None)\n",
    "    node[1].pop('osmid', None)\n",
    "    node[1].pop('name', None)\n",
    "    node[1].pop('highway', None)\n",
    "    node[1].pop('ref', None)\n",
    "    node[1].pop('aadt_dist', None)\n",
    "    node[1].pop('aadt_distance', None)\n",
    "\n",
    "    for key in list(node[1].keys()):\n",
    "        if type(node[1][key]) not in (int, float):\n",
    "            try:\n",
    "                node[1][key] = float(node[1][key])\n",
    "            except:\n",
    "                node[1].pop(key, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = []\n",
    "for node in H.nodes(data=True):\n",
    "    for key in node[1].keys():\n",
    "        if key not in all_feats:\n",
    "            all_feats.append(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in H.nodes(data=True):\n",
    "    for feat in all_feats:\n",
    "        if feat not in node[1].keys():\n",
    "            node[1][feat] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save node features in dataframe\n",
    "node_features = []\n",
    "for node in H.nodes(data=True):\n",
    "    node_features.append(node[1])\n",
    "node_features = pd.DataFrame(node_features).drop(columns=['aadt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list, x, y = [], [], []\n",
    "for node, feats in list(H.nodes(data=True)):\n",
    "    node_list.append(node)\n",
    "    x.append([feats[feat] for feat in all_feats if feat != 'aadt'])\n",
    "    y.append(feats['aadt'])\n",
    "\n",
    "node_idx = {node : idx for idx, node in enumerate(node_list)}\n",
    "edge_index = []\n",
    "for s, t in list(H.edges):\n",
    "    edge_index.append([node_idx[s], node_idx[t]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "linegraph = Data()\n",
    "linegraph.num_nodes = len(node_list)\n",
    "linegraph.x = x\n",
    "linegraph.y = y\n",
    "linegraph.edge_index = edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create file structure based on number of node features\n",
    "config_folder = glob.glob('../data/graphs/configs/*.txt')\n",
    "num_folder = None\n",
    "\n",
    "if len(config_folder) == 0:\n",
    "    print('Creating new folder')\n",
    "    os.mkdir('../data/graphs/1')\n",
    "    os.mkdir('../data/graphs/1/models')\n",
    "    with open('../data/graphs/configs/1.txt', 'w') as f:\n",
    "        f.write(f\"features: {' '.join(features)}\\n\")\n",
    "        f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "        f.write(f\"distance: {dist}\\n\")\n",
    "\n",
    "for file in config_folder:\n",
    "    same_features = False\n",
    "    same_expand_features = False\n",
    "    same_distance = False\n",
    "    with open(file, 'r') as f:\n",
    "        config = f.readlines()\n",
    "    for line in config:\n",
    "        if 'distance' in line:\n",
    "            if int(line.split(':')[-1]) == dist:\n",
    "                same_distance = True\n",
    "        if 'features' in line:\n",
    "            if set(line.split(':')[-1].split()) == set(features):\n",
    "                same_features = True\n",
    "        if 'expand_features' in line:\n",
    "            if set(line.split(':')[-1].split()) == set(expand_features):\n",
    "                same_expand_features = True\n",
    "    if same_distance and same_features and same_expand_features:\n",
    "        num_folder = file.split('/')[-1].split('.')[0]\n",
    "    else:\n",
    "        num_folder = len(config_folder) + 1\n",
    "        os.makedirs(f'../data/graphs/{num_folder}/models', exist_ok=True)\n",
    "        with open(f'../data/graphs/configs/{num_folder}.txt', 'w') as f:\n",
    "            f.write(f\"features: {' '.join(features)}\\n\")\n",
    "            f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "            f.write(f\"distance: {dist}\\n\")\n",
    "    # Ensure the directory exists before writing the file\n",
    "    os.makedirs(f'../data/graphs/{num_folder}', exist_ok=True)\n",
    "    with open(f'../data/graphs/{num_folder}/linegraph_tg.pkl', 'wb') as f:\n",
    "        pickle.dump(linegraph, f)\n",
    "    node_features.to_csv(f'../data/graphs/{num_folder}/node_features.csv', index=False)\n",
    "\n",
    "for file in config_folder:\n",
    "    same_features = False\n",
    "    same_expand_features = False\n",
    "    same_distance = False\n",
    "    with open(file, 'r') as f:\n",
    "        config = f.readlines()\n",
    "    for line in config:\n",
    "        if 'distance' in line:\n",
    "            if int(line.split(':')[-1]) == dist:\n",
    "                same_distance = True\n",
    "        if 'features' in line:\n",
    "            if set(line.split(':')[-1].split()) == set(features):\n",
    "                same_features = True\n",
    "        if 'expand_features' in line:\n",
    "            if set(line.split(':')[-1].split()) == set(expand_features):\n",
    "                same_expand_features = True\n",
    "    if same_distance and same_features and same_expand_features:\n",
    "        num_folder = file.split('/')[-1].split('.')[0]\n",
    "    else:\n",
    "        num_folder = len(config_folder) + 1\n",
    "        try:\n",
    "            os.mkdir(f'../data/graphs/{num_folder}')\n",
    "            os.mkdir(f'../data/graphs/{num_folder}/models')\n",
    "        except:\n",
    "            pass\n",
    "        with open(f'../data/graphs/configs/{num_folder}.txt', 'w') as f:\n",
    "            f.write(f\"features: {' '.join(features)}\\n\")\n",
    "            f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "            f.write(f\"distance: {dist}\\n\")\n",
    "    with open(f'../data/graphs/{num_folder}/linegraph_tg.pkl', 'wb') as f:\n",
    "        pickle.dump(linegraph, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
