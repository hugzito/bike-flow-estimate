{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline GCN testing\n",
    "Notebook to create and evaluate GCN against EBC on predicting number of passing bicyclists in *copenhagen?*\n",
    "- Preprocess EBC for graph DONE\n",
    "- Assign Metrics from data\n",
    "- Create Torch Graph\n",
    "- Evaluate against SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric as tg\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import shapely\n",
    "import momepy as mp \n",
    "import esda\n",
    "import seaborn as sns\n",
    "from shapely.strtree import STRtree\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, glob\n",
    "\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = 55.6867243, 12.5700724\n",
    "dist = 10000\n",
    "\n",
    "amenities = ox.features.features_from_point((lat, lon), tags={'shop' : True}, dist=dist)\n",
    "\n",
    "features = [\n",
    "    'aerialway',\n",
    "    'aeroway',\n",
    "    'amenity',\n",
    "    'barrier',\n",
    "    'boundary',\n",
    "    'building',\n",
    "    'craft',\n",
    "    'emergency',\n",
    "    'geological',\n",
    "    'healthcare',\n",
    "    'highway',\n",
    "    'historic',\n",
    "    'landuse',\n",
    "    'leisure',\n",
    "    'man_made',\n",
    "    'military',\n",
    "    'natural',\n",
    "    'office',\n",
    "    'place',\n",
    "    'power',\n",
    "    'public_transport',\n",
    "    'railway',\n",
    "    'route',\n",
    "    'shop',\n",
    "    'telecom',\n",
    "    'tourism',\n",
    "    'water',\n",
    "    'waterway',    \n",
    "]\n",
    "\n",
    "expand_features = [\n",
    "    'shop',\n",
    "    'route', \n",
    "    'highway', \n",
    "    'waterway', \n",
    "    'width', \n",
    "    'length', \n",
    "    'aerialway', \n",
    "    'power', \n",
    "    'healthcare'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_city_graph(lat, lon, dist, features, expand_features):\n",
    "#     g = ox.graph_from_point((lat, lon), dist=dist, network_type='bike', simplify=True, retain_all=False)\n",
    "#     feat_dict = {i : True for i in features}\n",
    "#     amenities = ox.features.features_from_point((lat, lon), tags=feat_dict, dist=dist)\n",
    "#     amenities = amenities[amenities.geometry.notnull()]\n",
    "#     amenities['new_col'] = np.nan\n",
    "\n",
    "#     for feat in features:\n",
    "#         if feat not in expand_features:\n",
    "#             amenities.loc[amenities[feat].notnull(), 'new_col'] = feat\n",
    "    \n",
    "#     amenities['amenity'] = amenities['new_col']\n",
    "\n",
    "#     for feat in expand_features:\n",
    "#         amenities['amenity'].fillna(amenities[feat], inplace=True)\n",
    "#     amenities = amenities[amenities['amenity'].notnull()]\n",
    "\n",
    "#     gdf = mp.nx_to_gdf(g, points=False, lines=True, spatial_weights=True).to_crs(epsg=3857)\n",
    "#     gdf = gdf[gdf.geometry.notnull()].reset_index(drop=True)\n",
    "#     return g, gdf, amenities\n",
    "\n",
    "g, gdf, amenities = get_city_graph(lat,\n",
    "                                    lon,\n",
    "                                    dist,\n",
    "                                    features = features, \n",
    "                                    expand_features = expand_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### carry weights over to line graph\n",
    "\n",
    "# def create_linegraph(g):\n",
    "#     g = nx.Graph(g)\n",
    "#     H = nx.line_graph(g)\n",
    "#     H.add_nodes_from((node, g.edges[node]) for node in H)   \n",
    "#     for s, t in H.edges:\n",
    "#         H.edges[s, t]['weight'] = g.edges[s]['length'] + g.edges[t]['length']\n",
    "#     return H\n",
    "\n",
    "H = create_linegraph(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_bc(shortest_paths, graph):\n",
    "#     bc = {i: 0 for i in graph.nodes}\n",
    "#     for node in tqdm(graph.nodes):\n",
    "#         for path in shortest_paths[node].values():\n",
    "#             for node_visited in set(path):\n",
    "#                 bc[node_visited] += 1\n",
    "#     total_nodes = graph.number_of_nodes() ** 2\n",
    "#     return {node: count / total_nodes for node, count in bc.items()}\n",
    "\n",
    "ebc = dict(nx.all_pairs_dijkstra_path(H,\n",
    "                                    weight='weight',\n",
    "                                    cutoff=1000,\n",
    "))\n",
    "bc = calc_bc(ebc, H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(H, bc, 'bc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aadt(filepath, g):\n",
    "    nodes, edges = mp.nx_to_gdf(g)\n",
    "    gdf2 = gpd.GeoDataFrame.from_file(filepath)\n",
    "    gdf2.set_crs(epsg=4326, inplace=True)\n",
    "    gdf2 = gdf2.to_crs(epsg=3857)\n",
    "    gdf2['geometry'] = gdf2['geometry']\n",
    "    # gdf2 = gdf2[gdf2['geometry'].within(gdf['geometry'])]\n",
    "    ### export only relevant columns\n",
    "    gdf_new = gdf2[['id', 'vejnavn', 'geometry', 'aadt_cykler']]\n",
    "    ### remove null values on aadt_cykler\n",
    "    gdf_new = gdf_new[gdf_new['aadt_cykler'].notnull()]\n",
    "    xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "    gdf_new = gdf_new.cx[xmin:xmax, ymin:ymax]\n",
    "    gdf_new.to_crs(epsg=4326, inplace=True)\n",
    "    return gdf_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestrings = [i[2]['geometry'] if 'geometry' in i[2] else None for i in list(g.edges(data=True))]\n",
    "from_node = [i[0] for i in list(g.edges(data=True))]\n",
    "to_node = [i[1] for i in list(g.edges(data=True))]\n",
    "\n",
    "tree = STRtree(linestrings)\n",
    "for i, row in tqdm(gdf_new.iterrows(), total=len(gdf_new)):\n",
    "    point = row['geometry']\n",
    "    if point is None:\n",
    "        continue\n",
    "    nearest_edge_idx = tree.nearest(point)\n",
    "    nearest_edge = linestrings[nearest_edge_idx]\n",
    "    nearest_edge_distance = nearest_edge.distance(point)\n",
    "    start_node = from_node[linestrings.index(nearest_edge)]\n",
    "    end_node = to_node[linestrings.index(nearest_edge)]\n",
    "    \n",
    "    # Ensure the edge exists in the graph\n",
    "    if (start_node, end_node) not in H.nodes():\n",
    "        if (end_node, start_node) not in H.nodes:\n",
    "            continue\n",
    "        else:\n",
    "            start_node, end_node = end_node, start_node\n",
    "\n",
    "    if 'aadt' not in H.nodes()[(start_node, end_node)]:\n",
    "        H.nodes()[(start_node, end_node)]['aadt'] = row['aadt_cykler']\n",
    "        H.nodes()[(start_node, end_node)]['aadt_distance'] = nearest_edge_distance\n",
    "    if 'aadt_distance' not in H.nodes()[(start_node, end_node)] or H.nodes()[(start_node, end_node)]['aadt_distance'] > nearest_edge_distance:\n",
    "        H.nodes()[(start_node, end_node)]['aadt'] = row['aadt_cykler']\n",
    "        H.nodes()[(start_node, end_node)]['aadt_distance'] = nearest_edge_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of nodes in H with the attribute 'aadt'\n",
    "print(f\"Number of nodes in H with 'aadt' attribute: {sum(1 for _, data in H.nodes(data=True) if 'aadt' in data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node, value in H.nodes(data=True):\n",
    "    if 'aadt' not in value.keys():\n",
    "        value['aadt'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amenities = amenities.reset_index()\n",
    "nodes = list((node, linestring) for node, linestring in H.nodes(data='geometry'))\n",
    "nodes = [node for node in nodes if node[1] is not None]\n",
    "linestrings = [linestring for node, linestring in nodes]\n",
    "nodes = [node for node, linestring in nodes]\n",
    "assert len(nodes) == len(linestrings)\n",
    "amenities['geometry'] = amenities['geometry'].apply(lambda x: x.centroid if x.geom_type == 'Polygon' else x)\n",
    "tree = STRtree(linestrings)\n",
    "for geom, amenity in zip(amenities['geometry'], amenities['amenity']):\n",
    "    nearest = tree.nearest(geom)\n",
    "    nearest = nodes[nearest]\n",
    "    if 'amenity' not in H.nodes[nearest]:\n",
    "        H.nodes[nearest]['amenity'] = [amenity]\n",
    "    else:\n",
    "        H.nodes[nearest]['amenity'].append(amenity)\n",
    "\n",
    "from collections import Counter\n",
    "for i in H.nodes(data=True):\n",
    "    if 'amenity' in i[1]:\n",
    "        amenity_counts = Counter(i[1]['amenity'])\n",
    "        for key in amenity_counts:\n",
    "            H.nodes[i[0]][key] = amenity_counts[key]\n",
    "        ## drop the amenity key\n",
    "        H.nodes[i[0]].pop('amenity', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in H.nodes(data=True):\n",
    "    node[1].pop('geometry', None)\n",
    "    # node[1].pop('osmid', None)\n",
    "    node[1].pop('name', None)\n",
    "    node[1].pop('highway', None)\n",
    "    node[1].pop('ref', None)\n",
    "    node[1].pop('aadt_dist', None)\n",
    "    node[1].pop('aadt_distance', None)\n",
    "\n",
    "    for key in list(node[1].keys()):\n",
    "        if type(node[1][key]) not in (int, float):\n",
    "            try:\n",
    "                node[1][key] = float(node[1][key])\n",
    "            except:\n",
    "                node[1].pop(key, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = []\n",
    "for node in H.nodes(data=True):\n",
    "    for key in node[1].keys():\n",
    "        if key not in all_feats:\n",
    "            all_feats.append(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in H.nodes(data=True):\n",
    "    for feat in all_feats:\n",
    "        if feat not in node[1].keys():\n",
    "            node[1][feat] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save node features in dataframe\n",
    "node_features = []\n",
    "for node in H.nodes(data=True):\n",
    "    node_features.append(node[1])\n",
    "node_features = pd.DataFrame(node_features).drop(columns=['aadt', 'osmid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list, x, y = [], [], []\n",
    "osmid_list = []\n",
    "for node, feats in list(H.nodes(data=True)):\n",
    "    node_list.append(node)\n",
    "    x.append([feats[feat] for feat in all_feats if feat not in ['aadt', 'osmid']])\n",
    "    y.append(feats['aadt'])\n",
    "    osmid_list.append(feats['osmid'])\n",
    "\n",
    "node_idx = {node : idx for idx, node in enumerate(node_list)}\n",
    "edge_index = []\n",
    "for s, t, data in H.edges(data=True):\n",
    "    edge_index.append([node_idx[s], node_idx[t]])\n",
    "\n",
    "# for s, t in list(H.edges):\n",
    "#     edge_index.append([node_idx[s], node_idx[t]])\n",
    "\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "linegraph = Data()\n",
    "linegraph.num_nodes = len(node_list)\n",
    "linegraph.x = x\n",
    "linegraph.y = y\n",
    "linegraph.osmid = torch.tensor(osmid_list, dtype=torch.long)\n",
    "linegraph.edge_index = edge_index\n",
    "linegraph.H = H\n",
    "# linegraph.g = g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert linegraph.edge_index.shape[0] == 2\n",
    "assert linegraph.edge_index.shape[1] == linegraph.edge_attr.shape[0] if 'edge_attr' in linegraph else True\n",
    "assert linegraph.x.shape[0] == linegraph.num_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# Find existing config files\n",
    "config_folder = glob.glob('../data/graphs/configs/*.txt')\n",
    "\n",
    "# Helper function to check if config matches\n",
    "def config_matches(file_path, features, expand_features, dist):\n",
    "    with open(file_path, 'r') as f:\n",
    "        config = f.readlines()\n",
    "    config_dict = {}\n",
    "    for line in config:\n",
    "        key, value = line.strip().split(':', 1)\n",
    "        config_dict[key.strip()] = set(value.strip().split()) if key != 'distance' else int(value.strip())\n",
    "\n",
    "    return (\n",
    "        config_dict.get('features', set()) == set(features) and\n",
    "        config_dict.get('expand_features', set()) == set(expand_features) and\n",
    "        config_dict.get('distance', None) == dist\n",
    "    )\n",
    "\n",
    "# Create initial folder if no config exists\n",
    "if not config_folder:\n",
    "    print('Creating new folder structure...')\n",
    "    os.makedirs('../data/graphs/1/models', exist_ok=True)\n",
    "    with open('../data/graphs/configs/1.txt', 'w') as f:\n",
    "        f.write(f\"features: {' '.join(features)}\\n\")\n",
    "        f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "        f.write(f\"distance: {dist}\\n\")\n",
    "    num_folder = '1'\n",
    "else:\n",
    "    # Check if a matching config already exists\n",
    "    num_folder = None\n",
    "    for file in config_folder:\n",
    "        if config_matches(file, features, expand_features, dist):\n",
    "            num_folder = os.path.splitext(os.path.basename(file))[0]\n",
    "            break\n",
    "\n",
    "    # If no matching config, create new one\n",
    "    if not num_folder:\n",
    "        num_folder = str(len(config_folder) + 1)\n",
    "        os.makedirs(f'../data/graphs/{num_folder}/models', exist_ok=True)\n",
    "        with open(f'../data/graphs/configs/{num_folder}.txt', 'w') as f:\n",
    "            f.write(f\"features: {' '.join(features)}\\n\")\n",
    "            f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "            f.write(f\"distance: {dist}\\n\")\n",
    "\n",
    "# Save graphs and node features\n",
    "os.makedirs(f'../data/graphs/{num_folder}', exist_ok=True)\n",
    "\n",
    "# Save torch geometric graph\n",
    "with open(f'../data/graphs/{num_folder}/linegraph_tg.pkl', 'wb') as f:\n",
    "    pickle.dump(linegraph, f)\n",
    "\n",
    "# Save corresponding networkx graph\n",
    "with open(f'../data/graphs/{num_folder}/linegraph_nx.pkl', 'wb') as f:\n",
    "    pickle.dump(H, f)\n",
    "\n",
    "# Save node features\n",
    "node_features.to_csv(f'../data/graphs/{num_folder}/node_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
