{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline GCN testing\n",
    "Notebook to create and evaluate GCN against EBC on predicting number of passing bicyclists in *copenhagen?*\n",
    "- Preprocess EBC for graph DONE\n",
    "- Assign Metrics from data\n",
    "- Create Torch Graph\n",
    "- Evaluate against SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric as tg\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import shapely\n",
    "import momepy as mp \n",
    "import esda\n",
    "import seaborn as sns\n",
    "from shapely.strtree import STRtree\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, glob\n",
    "\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = 55.6867243, 12.5700724\n",
    "dist = 10000\n",
    "\n",
    "amenities = ox.features.features_from_point((lat, lon), tags={'shop' : True}, dist=dist)\n",
    "\n",
    "features = [\n",
    "    'aerialway',\n",
    "    # 'aeroway',\n",
    "    # 'amenity',\n",
    "    # 'barrier',\n",
    "    # 'boundary',\n",
    "    # 'building',\n",
    "    # 'craft',\n",
    "    # 'emergency',\n",
    "    # 'geological',\n",
    "    # 'healthcare',\n",
    "    # 'highway',\n",
    "    # 'historic',\n",
    "    # 'landuse',\n",
    "    # 'leisure',\n",
    "    # 'man_made',\n",
    "    # 'military',\n",
    "    # 'natural',\n",
    "    # 'office',\n",
    "    # 'place',\n",
    "    # 'power',\n",
    "    # 'public_transport',\n",
    "    # 'railway',\n",
    "    # 'route',\n",
    "    'shop',\n",
    "    # 'telecom',\n",
    "    # 'tourism',\n",
    "    # 'water',\n",
    "    # 'waterway',    \n",
    "]\n",
    "\n",
    "expand_features = [\n",
    "    'shop',\n",
    "    # 'route', \n",
    "    # 'highway', \n",
    "    # 'waterway', \n",
    "    # 'width', \n",
    "    # 'length', \n",
    "    # 'aerialway', \n",
    "    # 'power', \n",
    "    # 'healthcare'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_graph(lat, lon, dist, features, expand_features):\n",
    "    g = ox.graph_from_point((lat, lon), dist=dist, network_type='bike', simplify=True, retain_all=False)\n",
    "    feat_dict = {i : True for i in features}\n",
    "    amenities = ox.features.features_from_point((lat, lon), tags=feat_dict, dist=dist)\n",
    "    amenities = amenities[amenities.geometry.notnull()]\n",
    "    amenities['new_col'] = np.nan\n",
    "\n",
    "    for feat in features:\n",
    "        if feat not in expand_features:\n",
    "            amenities.loc[amenities[feat].notnull(), 'new_col'] = feat\n",
    "    \n",
    "    amenities['amenity'] = amenities['new_col']\n",
    "\n",
    "    for feat in expand_features:\n",
    "        amenities['amenity'].fillna(amenities[feat], inplace=True)\n",
    "    amenities = amenities[amenities['amenity'].notnull()]\n",
    "\n",
    "    gdf = mp.nx_to_gdf(g, points=False, lines=True, spatial_weights=True).to_crs(epsg=3857)\n",
    "    gdf = gdf[gdf.geometry.notnull()].reset_index(drop=True)\n",
    "    return g, gdf, amenities\n",
    "\n",
    "g, gdf, amenities = get_city_graph(lat,\n",
    "                                    lon,\n",
    "                                    dist,\n",
    "                                    features = features, \n",
    "                                    expand_features = expand_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### carry weights over to line graph\n",
    "\n",
    "def create_linegraph(g):\n",
    "    g = nx.Graph(g)\n",
    "    H = nx.line_graph(g)\n",
    "    H.add_nodes_from((node, g.edges[node]) for node in H)   \n",
    "    for s, t in H.edges:\n",
    "        H.edges[s, t]['weight'] = g.edges[s]['length'] + g.edges[t]['length']\n",
    "    return H\n",
    "\n",
    "H = create_linegraph(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bc(graph):\n",
    "    ebc = dict(nx.all_pairs_dijkstra_path(graph,\n",
    "                                    weight='weight',\n",
    "                                    cutoff=1000,))\n",
    "    bc = {i: 0 for i in graph.nodes}\n",
    "    for node in tqdm(graph.nodes):\n",
    "        for path in ebc[node].values():\n",
    "            for node_visited in set(path):\n",
    "                bc[node_visited] += 1\n",
    "    total_nodes = graph.number_of_nodes() ** 2\n",
    "    return {node: count / total_nodes for node, count in bc.items()}\n",
    "\n",
    "bc = calc_bc(H)\n",
    "nx.set_node_attributes(H, bc, 'bc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aadt(filepath, g):\n",
    "    nodes, edges = mp.nx_to_gdf(g)\n",
    "    gdf2 = gpd.GeoDataFrame.from_file(filepath)\n",
    "    gdf2.set_crs(epsg=4326, inplace=True)\n",
    "    gdf2 = gdf2.to_crs(epsg=3857)\n",
    "    gdf2['geometry'] = gdf2['geometry']\n",
    "    # gdf2 = gdf2[gdf2['geometry'].within(gdf['geometry'])]\n",
    "    ### export only relevant columns\n",
    "    gdf_new = gdf2[['id', 'vejnavn', 'geometry', 'aadt_cykler']]\n",
    "    ### remove null values on aadt_cykler\n",
    "    gdf_new = gdf_new[gdf_new['aadt_cykler'].notnull()]\n",
    "    xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "    gdf_new = gdf_new.cx[xmin:xmax, ymin:ymax]\n",
    "    gdf_new.to_crs(epsg=4326, inplace=True)\n",
    "    return gdf_new\n",
    "\n",
    "gdf_new = load_aadt('../data/raw/trafiktaelling.json', g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_aadt_to_graph_edges(g, gdf_new, H, aadt_col='aadt_cykler'):\n",
    "    \"\"\"\n",
    "    Assigns AADT values from gdf_new to the nearest edge in graph H based on proximity.\n",
    "\n",
    "    Parameters:\n",
    "    - g: networkx graph with edge geometries.\n",
    "    - gdf_new: GeoDataFrame containing points and AADT values.\n",
    "    - H: networkx graph where AADT attributes will be assigned.\n",
    "    - aadt_col: column name in gdf_new containing the AADT values.\n",
    "    \"\"\"\n",
    "\n",
    "    edges_data = list(g.edges(data=True))\n",
    "    linestrings = [attr['geometry'] if 'geometry' in attr else None for _, _, attr in edges_data]\n",
    "    from_node = [u for u, _, _ in edges_data]\n",
    "    to_node = [v for _, v, _ in edges_data]\n",
    "\n",
    "    tree = STRtree(linestrings)\n",
    "\n",
    "    for i, row in tqdm(gdf_new.iterrows(), total=len(gdf_new)):\n",
    "        point = row['geometry']\n",
    "        if point is None:\n",
    "            continue\n",
    "\n",
    "        nearest_edge_idx = tree.nearest(point)\n",
    "        nearest_edge = linestrings[nearest_edge_idx]\n",
    "        nearest_edge_distance = nearest_edge.distance(point)\n",
    "\n",
    "        start_node = from_node[nearest_edge_idx]\n",
    "        end_node = to_node[nearest_edge_idx]\n",
    "\n",
    "        # Ensure the edge exists in H\n",
    "        if (start_node, end_node) not in H.nodes():\n",
    "            if (end_node, start_node) not in H.nodes():\n",
    "                continue\n",
    "            else:\n",
    "                start_node, end_node = end_node, start_node\n",
    "\n",
    "        node_pair = (start_node, end_node)\n",
    "\n",
    "        # Initialize or update AADT attributes if closer\n",
    "        if 'aadt' not in H.nodes()[node_pair]:\n",
    "            H.nodes()[node_pair]['aadt'] = row[aadt_col]\n",
    "            H.nodes()[node_pair]['aadt_distance'] = nearest_edge_distance\n",
    "        elif H.nodes()[node_pair]['aadt_distance'] > nearest_edge_distance:\n",
    "            H.nodes()[node_pair]['aadt'] = row[aadt_col]\n",
    "            H.nodes()[node_pair]['aadt_distance'] = nearest_edge_distance\n",
    "    return H\n",
    "\n",
    "H = assign_aadt_to_graph_edges(g, gdf_new, H, aadt_col='aadt_cykler')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linestrings = [i[2]['geometry'] if 'geometry' in i[2] else None for i in list(g.edges(data=True))]\n",
    "# from_node = [i[0] for i in list(g.edges(data=True))]\n",
    "# to_node = [i[1] for i in list(g.edges(data=True))]\n",
    "\n",
    "# tree = STRtree(linestrings)\n",
    "# for i, row in tqdm(gdf_new.iterrows(), total=len(gdf_new)):\n",
    "#     point = row['geometry']\n",
    "#     if point is None:\n",
    "#         continue\n",
    "#     nearest_edge_idx = tree.nearest(point)\n",
    "#     nearest_edge = linestrings[nearest_edge_idx]\n",
    "#     nearest_edge_distance = nearest_edge.distance(point)\n",
    "#     start_node = from_node[linestrings.index(nearest_edge)]\n",
    "#     end_node = to_node[linestrings.index(nearest_edge)]\n",
    "    \n",
    "#     # Ensure the edge exists in the graph\n",
    "#     if (start_node, end_node) not in H.nodes():\n",
    "#         if (end_node, start_node) not in H.nodes:\n",
    "#             continue\n",
    "#         else:\n",
    "#             start_node, end_node = end_node, start_node\n",
    "\n",
    "#     if 'aadt' not in H.nodes()[(start_node, end_node)]:\n",
    "#         H.nodes()[(start_node, end_node)]['aadt'] = row['aadt_cykler']\n",
    "#         H.nodes()[(start_node, end_node)]['aadt_distance'] = nearest_edge_distance\n",
    "#     if 'aadt_distance' not in H.nodes()[(start_node, end_node)] or H.nodes()[(start_node, end_node)]['aadt_distance'] > nearest_edge_distance:\n",
    "#         H.nodes()[(start_node, end_node)]['aadt'] = row['aadt_cykler']\n",
    "#         H.nodes()[(start_node, end_node)]['aadt_distance'] = nearest_edge_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of nodes in H with the attribute 'aadt'\n",
    "print(f\"Number of nodes in H with 'aadt' attribute: {sum(1 for _, data in H.nodes(data=True) if 'aadt' in data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node, value in H.nodes(data=True):\n",
    "    if 'aadt' not in value.keys():\n",
    "        value['aadt'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # amenities = amenities.reset_index()\n",
    "# nodes = list((node, linestring) for node, linestring in H.nodes(data='geometry'))\n",
    "# nodes = [node for node in nodes if node[1] is not None]\n",
    "# linestrings = [linestring for node, linestring in nodes]\n",
    "# nodes = [node for node, linestring in nodes]\n",
    "# assert len(nodes) == len(linestrings)\n",
    "# amenities['geometry'] = amenities['geometry'].apply(lambda x: x.centroid if x.geom_type == 'Polygon' else x)\n",
    "# tree = STRtree(linestrings)\n",
    "# for geom, amenity in zip(amenities['geometry'], amenities['amenity']):\n",
    "#     nearest = tree.nearest(geom)\n",
    "#     nearest = nodes[nearest]\n",
    "#     if 'amenity' not in H.nodes[nearest]:\n",
    "#         H.nodes[nearest]['amenity'] = [amenity]\n",
    "#     else:\n",
    "#         H.nodes[nearest]['amenity'].append(amenity)\n",
    "\n",
    "# from collections import Counter\n",
    "# for i in H.nodes(data=True):\n",
    "#     if 'amenity' in i[1]:\n",
    "#         amenity_counts = Counter(i[1]['amenity'])\n",
    "#         for key in amenity_counts:\n",
    "#             H.nodes[i[0]][key] = amenity_counts[key]\n",
    "#         ## drop the amenity key\n",
    "#         H.nodes[i[0]].pop('amenity', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_standardize_node_features(H, remove_fields=None):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes node attributes in a graph.\n",
    "    Removes specified fields, ensures all attributes are numeric floats, and fills missing features with 0.\n",
    "\n",
    "    Parameters:\n",
    "    - H: networkx graph.\n",
    "    - remove_fields: list of fields to remove (default common OSM fields).\n",
    "    \n",
    "    Returns:\n",
    "    - all_feats: list of all standardized features across nodes.\n",
    "    \"\"\"\n",
    "    if remove_fields is None:\n",
    "        remove_fields = ['geometry', 'name', 'highway', 'ref', 'aadt_dist', 'aadt_distance']\n",
    "\n",
    "    # Clean node attributes and convert to floats where possible\n",
    "    for node, data in H.nodes(data=True):\n",
    "        for field in remove_fields:\n",
    "            data.pop(field, None)\n",
    "\n",
    "        # Convert to float if possible, else remove\n",
    "        for key in list(data.keys()):\n",
    "            if not isinstance(data[key], (int, float)):\n",
    "                try:\n",
    "                    data[key] = float(data[key])\n",
    "                except (ValueError, TypeError):\n",
    "                    data.pop(key, None)\n",
    "\n",
    "    # Gather all unique features across all nodes\n",
    "    all_feats = set()\n",
    "    for _, data in H.nodes(data=True):\n",
    "        all_feats.update(data.keys())\n",
    "    all_feats = list(all_feats)\n",
    "\n",
    "    # Fill missing features with 0\n",
    "    for _, data in H.nodes(data=True):\n",
    "        for feat in all_feats:\n",
    "            data.setdefault(feat, 0)\n",
    "\n",
    "    return all_feats\n",
    "\n",
    "all_feats = clean_and_standardize_node_features(H, remove_fields=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node in H.nodes(data=True):\n",
    "#     node[1].pop('geometry', None)\n",
    "#     node[1].pop('name', None)\n",
    "#     node[1].pop('highway', None)\n",
    "#     node[1].pop('ref', None)\n",
    "#     node[1].pop('aadt_dist', None)\n",
    "#     node[1].pop('aadt_distance', None)\n",
    "\n",
    "#     for key in list(node[1].keys()):\n",
    "#         if type(node[1][key]) not in (int, float):\n",
    "#             try:\n",
    "#                 node[1][key] = float(node[1][key])\n",
    "#             except:\n",
    "#                 node[1].pop(key, None)\n",
    "\n",
    "# all_feats = []\n",
    "# for node in H.nodes(data=True):\n",
    "#     for key in node[1].keys():\n",
    "#         if key not in all_feats:\n",
    "#             all_feats.append(key)\n",
    "\n",
    "\n",
    "# for node in H.nodes(data=True):\n",
    "#     for feat in all_feats:\n",
    "#         if feat not in node[1].keys():\n",
    "#             node[1][feat] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save node features in dataframe\n",
    "node_features = []\n",
    "for node in H.nodes(data=True):\n",
    "    node_features.append(node[1])\n",
    "node_features = pd.DataFrame(node_features).drop(columns=['aadt', 'osmid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_list, x, y = [], [], []\n",
    "# osmid_list = []\n",
    "# for node, feats in list(H.nodes(data=True)):\n",
    "#     node_list.append(node)\n",
    "#     x.append([feats[feat] for feat in all_feats if feat not in ['aadt', 'osmid']])\n",
    "#     y.append(feats['aadt'])\n",
    "#     osmid_list.append(feats['osmid'])\n",
    "\n",
    "# node_idx = {node : idx for idx, node in enumerate(node_list)}\n",
    "# edge_index = []\n",
    "# for s, t, data in H.edges(data=True):\n",
    "#     edge_index.append([node_idx[s], node_idx[t]])\n",
    "\n",
    "# # for s, t in list(H.edges):\n",
    "# #     edge_index.append([node_idx[s], node_idx[t]])\n",
    "\n",
    "\n",
    "# edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n",
    "# x = torch.tensor(x, dtype=torch.float)\n",
    "# y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "# linegraph = Data()\n",
    "# linegraph.num_nodes = len(node_list)\n",
    "# linegraph.x = x\n",
    "# linegraph.y = y\n",
    "# linegraph.osmid = torch.tensor(osmid_list, dtype=torch.long)\n",
    "# linegraph.edge_index = edge_index\n",
    "# linegraph.H = H\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def graph_to_linegraph_data(H, all_feats, target_feat='aadt', osmid_feat='osmid'):\n",
    "    \"\"\"\n",
    "    Converts a networkx graph H with node and edge attributes into a PyTorch Geometric Data object.\n",
    "    \n",
    "    Parameters:\n",
    "    - H: networkx graph with node features.\n",
    "    - all_feats: list of feature names to extract from nodes.\n",
    "    - target_feat: feature to use as the target variable (default 'aadt').\n",
    "    - osmid_feat: feature to use as osmid identifier (default 'osmid').\n",
    "    \n",
    "    Returns:\n",
    "    - PyTorch Geometric Data object with node features, targets, osmid, and edge index.\n",
    "    \"\"\"\n",
    "    node_list, x, y, osmid_list = [], [], [], []\n",
    "\n",
    "    for node, feats in H.nodes(data=True):\n",
    "        node_list.append(node)\n",
    "        x.append([feats.get(feat, 0.0) for feat in all_feats if feat not in [target_feat, osmid_feat]])\n",
    "        y.append(feats[target_feat])\n",
    "        osmid_list.append(feats[osmid_feat])\n",
    "\n",
    "    node_idx = {node: idx for idx, node in enumerate(node_list)}\n",
    "\n",
    "    edge_index = [[node_idx[s], node_idx[t]] for s, t in H.edges()]\n",
    "\n",
    "    data = Data()\n",
    "    data.num_nodes = len(node_list)\n",
    "    data.x = torch.tensor(x, dtype=torch.float)\n",
    "    data.y = torch.tensor(y, dtype=torch.float)\n",
    "    data.osmid = torch.tensor(osmid_list, dtype=torch.long)\n",
    "    data.edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n",
    "    data.H = H  # Optional: Attach original H graph if needed\n",
    "\n",
    "    return data\n",
    "\n",
    "linegraph = graph_to_linegraph_data(H, all_feats, target_feat='aadt', osmid_feat='osmid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert linegraph.edge_index.shape[0] == 2\n",
    "assert linegraph.edge_index.shape[1] == linegraph.edge_attr.shape[0] if 'edge_attr' in linegraph else True\n",
    "assert linegraph.x.shape[0] == linegraph.num_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import pickle\n",
    "\n",
    "# # Find existing config files\n",
    "# config_folder = glob.glob('../data/graphs/configs/*.txt')\n",
    "\n",
    "# # Helper function to check if config matches\n",
    "# def config_matches(file_path, features, expand_features, dist):\n",
    "#     with open(file_path, 'r') as f:\n",
    "#         config = f.readlines()\n",
    "#     config_dict = {}\n",
    "#     for line in config:\n",
    "#         key, value = line.strip().split(':', 1)\n",
    "#         config_dict[key.strip()] = set(value.strip().split()) if key != 'distance' else int(value.strip())\n",
    "\n",
    "#     return (\n",
    "#         config_dict.get('features', set()) == set(features) and\n",
    "#         config_dict.get('expand_features', set()) == set(expand_features) and\n",
    "#         config_dict.get('distance', None) == dist\n",
    "#     )\n",
    "\n",
    "# # Create initial folder if no config exists\n",
    "# if not config_folder:\n",
    "#     print('Creating new folder structure...')\n",
    "#     os.makedirs('../data/graphs/1/models', exist_ok=True)\n",
    "#     with open('../data/graphs/configs/1.txt', 'w') as f:\n",
    "#         f.write(f\"features: {' '.join(features)}\\n\")\n",
    "#         f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "#         f.write(f\"distance: {dist}\\n\")\n",
    "#     num_folder = '1'\n",
    "# else:\n",
    "#     # Check if a matching config already exists\n",
    "#     num_folder = None\n",
    "#     for file in config_folder:\n",
    "#         if config_matches(file, features, expand_features, dist):\n",
    "#             num_folder = os.path.splitext(os.path.basename(file))[0]\n",
    "#             break\n",
    "\n",
    "#     # If no matching config, create new one\n",
    "#     if not num_folder:\n",
    "#         num_folder = str(len(config_folder) + 1)\n",
    "#         os.makedirs(f'../data/graphs/{num_folder}/models', exist_ok=True)\n",
    "#         with open(f'../data/graphs/configs/{num_folder}.txt', 'w') as f:\n",
    "#             f.write(f\"features: {' '.join(features)}\\n\")\n",
    "#             f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "#             f.write(f\"distance: {dist}\\n\")\n",
    "\n",
    "# # Save graphs and node features\n",
    "# os.makedirs(f'../data/graphs/{num_folder}', exist_ok=True)\n",
    "\n",
    "# # Save torch geometric graph\n",
    "# with open(f'../data/graphs/{num_folder}/linegraph_tg.pkl', 'wb') as f:\n",
    "#     pickle.dump(linegraph, f)\n",
    "\n",
    "# # Save corresponding networkx graph\n",
    "# with open(f'../data/graphs/{num_folder}/linegraph_nx.pkl', 'wb') as f:\n",
    "#     pickle.dump(H, f)\n",
    "\n",
    "# # Save node features\n",
    "# node_features.to_csv(f'../data/graphs/{num_folder}/node_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "def save_graph_with_config(\n",
    "    linegraph, \n",
    "    H, \n",
    "    node_features, \n",
    "    features, \n",
    "    expand_features, \n",
    "    dist, \n",
    "    base_path='../data/graphs'\n",
    "):\n",
    "    \"\"\"\n",
    "    Save graph data, networkx graph, and node features into a structured folder.\n",
    "    Uses config files to check for existing setups, creates new folders if needed.\n",
    "\n",
    "    Parameters:\n",
    "    - linegraph: PyTorch Geometric Data object.\n",
    "    - H: NetworkX graph object.\n",
    "    - node_features: DataFrame of node features.\n",
    "    - features: list of features.\n",
    "    - expand_features: list of expanded features.\n",
    "    - dist: distance parameter.\n",
    "    - base_path: base path to store the graphs and configs.\n",
    "    \n",
    "    Returns:\n",
    "    - num_folder (str): The assigned folder number where data was saved.\n",
    "    \"\"\"\n",
    "    config_folder = glob.glob(f'{base_path}/configs/*.txt')\n",
    "\n",
    "    def config_matches(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            config = f.readlines()\n",
    "        config_dict = {}\n",
    "        for line in config:\n",
    "            key, value = line.strip().split(':', 1)\n",
    "            config_dict[key.strip()] = set(value.strip().split()) if key != 'distance' else int(value.strip())\n",
    "\n",
    "        return (\n",
    "            config_dict.get('features', set()) == set(features) and\n",
    "            config_dict.get('expand_features', set()) == set(expand_features) and\n",
    "            config_dict.get('distance', None) == dist\n",
    "        )\n",
    "\n",
    "    # Determine folder number\n",
    "    if not config_folder:\n",
    "        print('Creating initial folder structure...')\n",
    "        num_folder = '1'\n",
    "    else:\n",
    "        num_folder = None\n",
    "        for file in config_folder:\n",
    "            if config_matches(file):\n",
    "                num_folder = os.path.splitext(os.path.basename(file))[0]\n",
    "                break\n",
    "        if not num_folder:\n",
    "            num_folder = str(len(config_folder) + 1)\n",
    "\n",
    "    # Create necessary folders and save configs\n",
    "    os.makedirs(f'{base_path}/{num_folder}/models', exist_ok=True)\n",
    "    with open(f'{base_path}/configs/{num_folder}.txt', 'w') as f:\n",
    "        f.write(f\"features: {' '.join(features)}\\n\")\n",
    "        f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "        f.write(f\"distance: {dist}\\n\")\n",
    "\n",
    "    # Save data\n",
    "    with open(f'{base_path}/{num_folder}/linegraph_tg.pkl', 'wb') as f:\n",
    "        pickle.dump(linegraph, f)\n",
    "\n",
    "    with open(f'{base_path}/{num_folder}/linegraph_nx.pkl', 'wb') as f:\n",
    "        pickle.dump(H, f)\n",
    "\n",
    "    node_features.to_csv(f'{base_path}/{num_folder}/node_features.csv', index=False)\n",
    "\n",
    "    print(f\"Graph and data saved in folder {num_folder}\")\n",
    "    return num_folder\n",
    "\n",
    "save_graph_with_config(\n",
    "    linegraph, \n",
    "    H, \n",
    "    node_features, \n",
    "    features, \n",
    "    expand_features, \n",
    "    dist\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
