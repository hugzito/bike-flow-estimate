{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline GCN testing\n",
    "Notebook to create and evaluate GCN against EBC on predicting number of passing bicyclists in *copenhagen?*\n",
    "- Preprocess EBC for graph DONE\n",
    "- Assign Metrics from data\n",
    "- Create Torch Graph\n",
    "- Evaluate against SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/7n/1v9m4ykn66ddbcxt5nwgg9280000gn/T/ipykernel_4951/2130356013.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/christianrasmussen/Documents/thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric as tg\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import shapely\n",
    "import momepy as mp \n",
    "import esda\n",
    "import seaborn as sns\n",
    "from shapely.strtree import STRtree\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, glob\n",
    "\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = 55.6867243, 12.5700724\n",
    "dist = 10000\n",
    "features = [\n",
    "    'amenity',\n",
    "    'shop',\n",
    "    'building',\n",
    "    # 'aerialway',\n",
    "    # 'aeroway', \n",
    "    # 'barrier', \n",
    "    # 'boundary', \n",
    "    # 'craft', \n",
    "    # 'emergency', \n",
    "    # 'highway', \n",
    "    # 'historic',\n",
    "    # 'landuse', \n",
    "    # 'leisure', \n",
    "    # 'healthcare', \n",
    "    # 'military',\n",
    "    'natural',\n",
    "    # 'office',\n",
    "    # 'power',\n",
    "    # 'public_transport',\n",
    "    # 'railway',\n",
    "    # 'place',\n",
    "    # 'service', \n",
    "    # 'tourism', \n",
    "    # 'waterway', \n",
    "    # 'route', \n",
    "    # 'water'\n",
    "]\n",
    "expand_features = ['shop', 'route', 'highway', 'waterway', 'width', 'length', 'aerialway', 'power', 'healthcare']\n",
    "expand_features = features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in ['shop', 'route', 'highway', 'waterway', 'width', 'length', 'aerialway', 'power', 'healthcare']:\n",
    "# \tif item in features:\n",
    "# \t\tfeatures.remove(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7n/1v9m4ykn66ddbcxt5nwgg9280000gn/T/ipykernel_4951/3141911894.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'amenity' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  amenities.loc[amenities[feat].notnull(), 'new_col'] = feat\n",
      "/var/folders/7n/1v9m4ykn66ddbcxt5nwgg9280000gn/T/ipykernel_4951/3141911894.py:18: UserWarning: Approach is not set. Defaulting to 'primal'.\n",
      "  gdf = mp.nx_to_gdf(g, points=False, lines=True, spatial_weights=True).to_crs(epsg=3857)\n"
     ]
    }
   ],
   "source": [
    "def get_city_graph(lat, lon, dist, features, expand_features):\n",
    "    g = ox.graph_from_point((lat, lon), dist=dist, network_type='bike', simplify=True, retain_all=False)\n",
    "    feat_dict = {i : True for i in features}\n",
    "    amenities = ox.features.features_from_point((lat, lon), tags=feat_dict, dist=dist)\n",
    "    amenities = amenities[amenities.geometry.notnull()]\n",
    "    amenities['new_col'] = np.nan\n",
    "\n",
    "    for feat in features:\n",
    "        if feat not in expand_features:\n",
    "            amenities.loc[amenities[feat].notnull(), 'new_col'] = feat\n",
    "    \n",
    "    amenities['amenity'] = amenities['new_col']\n",
    "\n",
    "    for feat in expand_features:\n",
    "        amenities['amenity'].fillna(amenities[feat], inplace=True)\n",
    "    amenities = amenities[amenities['amenity'].notnull()]\n",
    "\n",
    "    gdf = mp.nx_to_gdf(g, points=False, lines=True, spatial_weights=True).to_crs(epsg=3857)\n",
    "    gdf = gdf[gdf.geometry.notnull()].reset_index(drop=True)\n",
    "    return g, gdf, amenities\n",
    "\n",
    "g, gdf, amenities = get_city_graph(lat,\n",
    "                                    lon,\n",
    "                                    dist,\n",
    "                                    features = features, \n",
    "                                    expand_features = expand_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### carry weights over to line graph\n",
    "\n",
    "def create_linegraph(g):\n",
    "    g = nx.Graph(g)\n",
    "    H = nx.line_graph(g)\n",
    "    H.add_nodes_from((node, g.edges[node]) for node in H)   \n",
    "    for s, t in H.edges:\n",
    "        H.edges[(s, t)]['weight'] = g.edges[s]['length'] + g.edges[t]['length']\n",
    "    return H\n",
    "\n",
    "H = create_linegraph(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78168/78168 [00:29<00:00, 2672.34it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def calc_bc(shortest_paths, graph):\n",
    "    bc = {i: 0 for i in graph.nodes}\n",
    "    for node in tqdm(graph.nodes):\n",
    "        for path in shortest_paths[node].values():\n",
    "            for node_visited in set(path):\n",
    "                bc[node_visited] += 1\n",
    "    total_nodes = graph.number_of_nodes() ** 2\n",
    "    return {node: count / total_nodes for node, count in bc.items()}\n",
    "\n",
    "ebc = dict(nx.all_pairs_dijkstra_path(H,\n",
    "                                    weight='weight',\n",
    "                                    cutoff=1000,\n",
    "))\n",
    "bc = calc_bc(ebc, H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc2 = {}\n",
    "for x, y in bc:\n",
    "    bc2[(x, y)] = bc[(x, y)]\n",
    "\n",
    "nx.set_node_attributes(H, bc2, 'bc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7n/1v9m4ykn66ddbcxt5nwgg9280000gn/T/ipykernel_4951/2736184080.py:1: UserWarning: Approach is not set. Defaulting to 'primal'.\n",
      "  nodes, edges = mp.nx_to_gdf(g)\n"
     ]
    }
   ],
   "source": [
    "nodes, edges = mp.nx_to_gdf(g)\n",
    "filepath = '../data/raw/trafiktaelling.json'\n",
    "gdf2 = gpd.GeoDataFrame.from_file(filepath)\n",
    "gdf2.set_crs(epsg=4326, inplace=True)\n",
    "gdf2 = gdf2.to_crs(epsg=3857)\n",
    "gdf2['geometry'] = gdf2['geometry']\n",
    "# gdf2 = gdf2[gdf2['geometry'].within(gdf['geometry'])]\n",
    "### export only relevant columns\n",
    "gdf_new = gdf2[['id', 'vejnavn', 'geometry', 'aadt_cykler']]\n",
    "### remove null values on aadt_cykler\n",
    "gdf_new = gdf_new[gdf_new['aadt_cykler'].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "gdf_new = gdf_new.cx[xmin:xmax, ymin:ymax]\n",
    "gdf_new.to_crs(epsg=4326, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 670/670 [09:22<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "linestrings = [i[2]['geometry'] if 'geometry' in i[2] else None for i in list(g.edges(data=True))]\n",
    "from_node = [i[0] for i in list(g.edges(data=True))]\n",
    "to_node = [i[1] for i in list(g.edges(data=True))]\n",
    "\n",
    "tree = STRtree(linestrings)\n",
    "for i, row in tqdm(gdf_new.iterrows(), total=len(gdf_new)):\n",
    "    point = row['geometry']\n",
    "    if point is None:\n",
    "        continue\n",
    "    nearest_edge_idx = tree.nearest(point)\n",
    "    nearest_edge = linestrings[nearest_edge_idx]\n",
    "    nearest_edge_distance = nearest_edge.distance(point)\n",
    "    start_node = from_node[linestrings.index(nearest_edge)]\n",
    "    end_node = to_node[linestrings.index(nearest_edge)]\n",
    "    \n",
    "    # Ensure the edge exists in the graph\n",
    "    if (start_node, end_node) not in H.nodes():\n",
    "        if (end_node, start_node) not in H.nodes:\n",
    "            continue\n",
    "        else:\n",
    "            start_node, end_node = end_node, start_node\n",
    "\n",
    "    if 'aadt' not in H.nodes()[(start_node, end_node)]:\n",
    "        H.nodes()[(start_node, end_node)]['aadt'] = row['aadt_cykler']\n",
    "        H.nodes()[(start_node, end_node)]['aadt_distance'] = nearest_edge_distance\n",
    "    if 'aadt_distance' not in H.nodes()[(start_node, end_node)] or H.nodes()[(start_node, end_node)]['aadt_distance'] > nearest_edge_distance:\n",
    "        H.nodes()[(start_node, end_node)]['aadt'] = row['aadt_cykler']\n",
    "        H.nodes()[(start_node, end_node)]['aadt_distance'] = nearest_edge_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node, value in H.nodes(data=True):\n",
    "    if 'aadt' not in value.keys():\n",
    "        value['aadt'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amenities = amenities.reset_index()\n",
    "nodes = list((node, linestring) for node, linestring in H.nodes(data='geometry'))\n",
    "nodes = [node for node in nodes if node[1] is not None]\n",
    "linestrings = [linestring for node, linestring in nodes]\n",
    "nodes = [node for node, linestring in nodes]\n",
    "assert len(nodes) == len(linestrings)\n",
    "amenities['geometry'] = amenities['geometry'].apply(lambda x: x.centroid if x.geom_type == 'Polygon' else x)\n",
    "tree = STRtree(linestrings)\n",
    "for geom, amenity in zip(amenities['geometry'], amenities['amenity']):\n",
    "    nearest = tree.nearest(geom)\n",
    "    nearest = nodes[nearest]\n",
    "    if 'amenity' not in H.nodes[nearest]:\n",
    "        H.nodes[nearest]['amenity'] = [amenity]\n",
    "    else:\n",
    "        H.nodes[nearest]['amenity'].append(amenity)\n",
    "\n",
    "from collections import Counter\n",
    "for i in H.nodes(data=True):\n",
    "    if 'amenity' in i[1]:\n",
    "        amenity_counts = Counter(i[1]['amenity'])\n",
    "        for key in amenity_counts:\n",
    "            H.nodes[i[0]][key] = amenity_counts[key]\n",
    "        ## drop the amenity key\n",
    "        H.nodes[i[0]].pop('amenity', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in H.nodes(data=True):\n",
    "    node[1].pop('geometry', None)\n",
    "    node[1].pop('osmid', None)\n",
    "    node[1].pop('name', None)\n",
    "    node[1].pop('highway', None)\n",
    "    node[1].pop('ref', None)\n",
    "    node[1].pop('aadt_dist', None)\n",
    "    node[1].pop('aadt_distance', None)\n",
    "\n",
    "    for key in list(node[1].keys()):\n",
    "        if type(node[1][key]) not in (int, float):\n",
    "            try:\n",
    "                node[1][key] = float(node[1][key])\n",
    "            except:\n",
    "                node[1].pop(key, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = []\n",
    "for node in H.nodes(data=True):\n",
    "    for key in node[1].keys():\n",
    "        if key not in all_feats:\n",
    "            all_feats.append(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in H.nodes(data=True):\n",
    "    for feat in all_feats:\n",
    "        if feat not in node[1].keys():\n",
    "            node[1][feat] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save node features in dataframe\n",
    "node_features = []\n",
    "for node in H.nodes(data=True):\n",
    "    node_features.append(node[1])\n",
    "node_features = pd.DataFrame(node_features).drop(columns=['aadt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list, x, y = [], [], []\n",
    "for node, feats in list(H.nodes(data=True)):\n",
    "    node_list.append(node)\n",
    "    x.append([feats[feat] for feat in all_feats if feat != 'aadt'])\n",
    "    y.append(feats['aadt'])\n",
    "\n",
    "node_idx = {node : idx for idx, node in enumerate(node_list)}\n",
    "edge_index = []\n",
    "for s, t in list(H.edges):\n",
    "    edge_index.append([node_idx[s], node_idx[t]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "linegraph = Data()\n",
    "linegraph.num_nodes = len(node_list)\n",
    "linegraph.x = x\n",
    "linegraph.y = y\n",
    "linegraph.edge_index = edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### create file structure based on number of node features\n",
    "# config_folder = glob.glob('../data/graphs/configs/*.txt')\n",
    "# num_folder = None\n",
    "\n",
    "# if len(config_folder) == 0:\n",
    "#     print('Creating new folder')\n",
    "#     os.mkdir('../data/graphs/1')\n",
    "#     os.mkdir('../data/graphs/1/models')\n",
    "#     with open('../data/graphs/configs/1.txt', 'w') as f:\n",
    "#         f.write(f\"features: {' '.join(features)}\\n\")\n",
    "#         f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "#         f.write(f\"distance: {dist}\\n\")\n",
    "\n",
    "# for file in config_folder:\n",
    "#     same_features = False\n",
    "#     same_expand_features = False\n",
    "#     same_distance = False\n",
    "#     with open(file, 'r') as f:\n",
    "#         config = f.readlines()\n",
    "#     for line in config:\n",
    "#         if 'distance' in line:\n",
    "#             if int(line.split(':')[-1]) == dist:\n",
    "#                 same_distance = True\n",
    "#         if 'features' in line:\n",
    "#             if set(line.split(':')[-1].split()) == set(features):\n",
    "#                 same_features = True\n",
    "#         if 'expand_features' in line:\n",
    "#             if set(line.split(':')[-1].split()) == set(expand_features):\n",
    "#                 same_expand_features = True\n",
    "#     if same_distance and same_features and same_expand_features:\n",
    "#         num_folder = file.split('/')[-1].split('.')[0]\n",
    "#     else:\n",
    "#         num_folder = len(config_folder) + 1\n",
    "#         os.makedirs(f'../data/graphs/{num_folder}/models', exist_ok=True)\n",
    "#         with open(f'../data/graphs/configs/{num_folder}.txt', 'w') as f:\n",
    "#             f.write(f\"features: {' '.join(features)}\\n\")\n",
    "#             f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "#             f.write(f\"distance: {dist}\\n\")\n",
    "#     # Ensure the directory exists before writing the file\n",
    "#     os.makedirs(f'../data/graphs/{num_folder}', exist_ok=True)\n",
    "#     with open(f'../data/graphs/{num_folder}/linegraph_tg.pkl', 'wb') as f:\n",
    "#         pickle.dump(linegraph, f)\n",
    "#     node_features.to_csv(f'../data/graphs/{num_folder}/node_features.csv', index=False)\n",
    "\n",
    "# for file in config_folder:\n",
    "#     same_features = False\n",
    "#     same_expand_features = False\n",
    "#     same_distance = False\n",
    "#     with open(file, 'r') as f:\n",
    "#         config = f.readlines()\n",
    "#     for line in config:\n",
    "#         if 'distance' in line:\n",
    "#             if int(line.split(':')[-1]) == dist:\n",
    "#                 same_distance = True\n",
    "#         if 'features' in line:\n",
    "#             if set(line.split(':')[-1].split()) == set(features):\n",
    "#                 same_features = True\n",
    "#         if 'expand_features' in line:\n",
    "#             if set(line.split(':')[-1].split()) == set(expand_features):\n",
    "#                 same_expand_features = True\n",
    "#     if same_distance and same_features and same_expand_features:\n",
    "#         num_folder = file.split('/')[-1].split('.')[0]\n",
    "#     else:\n",
    "#         num_folder = len(config_folder) + 1\n",
    "#         try:\n",
    "#             os.mkdir(f'../data/graphs/{num_folder}')\n",
    "#             os.mkdir(f'../data/graphs/{num_folder}/models')\n",
    "#         except:\n",
    "#             pass\n",
    "#         with open(f'../data/graphs/configs/{num_folder}.txt', 'w') as f:\n",
    "#             f.write(f\"features: {' '.join(features)}\\n\")\n",
    "#             f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "#             f.write(f\"distance: {dist}\\n\")\n",
    "#     with open(f'../data/graphs/{num_folder}/linegraph_tg.pkl', 'wb') as f:\n",
    "#         pickle.dump(linegraph, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# Find existing config files\n",
    "config_folder = glob.glob('../data/graphs/configs/*.txt')\n",
    "\n",
    "# Helper function to check if config matches\n",
    "def config_matches(file_path, features, expand_features, dist):\n",
    "    with open(file_path, 'r') as f:\n",
    "        config = f.readlines()\n",
    "    config_dict = {}\n",
    "    for line in config:\n",
    "        key, value = line.strip().split(':', 1)\n",
    "        config_dict[key.strip()] = set(value.strip().split()) if key != 'distance' else int(value.strip())\n",
    "\n",
    "    return (\n",
    "        config_dict.get('features', set()) == set(features) and\n",
    "        config_dict.get('expand_features', set()) == set(expand_features) and\n",
    "        config_dict.get('distance', None) == dist\n",
    "    )\n",
    "\n",
    "# Create initial folder if no config exists\n",
    "if not config_folder:\n",
    "    print('Creating new folder structure...')\n",
    "    os.makedirs('../data/graphs/1/models', exist_ok=True)\n",
    "    with open('../data/graphs/configs/1.txt', 'w') as f:\n",
    "        f.write(f\"features: {' '.join(features)}\\n\")\n",
    "        f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "        f.write(f\"distance: {dist}\\n\")\n",
    "    num_folder = '1'\n",
    "else:\n",
    "    # Check if a matching config already exists\n",
    "    num_folder = None\n",
    "    for file in config_folder:\n",
    "        if config_matches(file, features, expand_features, dist):\n",
    "            num_folder = os.path.splitext(os.path.basename(file))[0]\n",
    "            break\n",
    "\n",
    "    # If no matching config, create new one\n",
    "    if not num_folder:\n",
    "        num_folder = str(len(config_folder) + 1)\n",
    "        os.makedirs(f'../data/graphs/{num_folder}/models', exist_ok=True)\n",
    "        with open(f'../data/graphs/configs/{num_folder}.txt', 'w') as f:\n",
    "            f.write(f\"features: {' '.join(features)}\\n\")\n",
    "            f.write(f\"expand_features: {' '.join(expand_features)}\\n\")\n",
    "            f.write(f\"distance: {dist}\\n\")\n",
    "\n",
    "# Save graph and node features\n",
    "os.makedirs(f'../data/graphs/{num_folder}', exist_ok=True)\n",
    "with open(f'../data/graphs/{num_folder}/linegraph_tg.pkl', 'wb') as f:\n",
    "    pickle.dump(linegraph, f)\n",
    "\n",
    "node_features.to_csv(f'../data/graphs/{num_folder}/node_features.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
