{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline GCN testing\n",
    "Notebook to create and evaluate GCN against EBC on predicting number of passing bicyclists in *copenhagen?*\n",
    "- Preprocess EBC for graph DONE\n",
    "- Assign Metrics from data\n",
    "- Create Torch Graph\n",
    "- Evaluate against SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric as tg\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import shapely\n",
    "import momepy as mp \n",
    "import esda\n",
    "import seaborn as sns\n",
    "from shapely.strtree import STRtree\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lat, lon = 55.6867243, 12.5700724\n",
    "\n",
    "def get_city_graph(lat, lon, dist, features = ['amenity', 'shop', 'building']):\n",
    "    g = ox.graph_from_point((lat, lon), dist=dist, network_type='bike', simplify=True, retain_all=False)\n",
    "    feat_dict = {i : True for i in features}\n",
    "    amenities = ox.features.features_from_point((lat, lon), tags=feat_dict, dist=dist)\n",
    "    amenities = amenities[amenities.geometry.notnull()]\n",
    "    for feat in features:\n",
    "        amenities['amenity'].fillna(amenities[feat], inplace=True)\n",
    "        print(amenities['amenity'].isnull().sum())\n",
    "    amenities = amenities[amenities['amenity'].notnull()]\n",
    "    # amenities = amenities.to_crs(epsg=3857)\n",
    "    gdf = mp.nx_to_gdf(g, points=False, lines=True, spatial_weights=True).to_crs(epsg=3857)\n",
    "    ### remove rows with geometry == None\n",
    "    gdf = gdf[gdf.geometry.notnull()]\n",
    "    gdf = gdf.reset_index(drop=True)\n",
    "    return g, gdf, amenities\n",
    "\n",
    "features = ['amenity', 'shop', 'building',\n",
    "            'aerialway', 'aeroway', 'barrier', 'boundary', 'craft', 'emergency', 'geological', 'highway', 'historic',\n",
    "            'landuse', 'leisure', 'healthcare', 'military', 'natural', 'office', 'power', 'public_transport', 'railway',\n",
    "            'place', 'service', 'tourism', 'waterway', 'route', 'water']\n",
    "\n",
    "g, gdf, amenities = get_city_graph(lat, lon, 10000, features = features)\n",
    "\n",
    "### plot the graph\n",
    "fig, ax = ox.plot_graph(g, node_size=0, edge_linewidth=0.5, show=False, close=False)\n",
    "gdf.plot(ax=ax, linewidth=1, edgecolor='black')\n",
    "\n",
    "import nx_parallel as nxp\n",
    "import networkx as nx\n",
    "\n",
    "# enabling networkx's config for nx-parallel\n",
    "nx.config.backends.parallel.active = True\n",
    "\n",
    "# setting `n_jobs` (by default, `n_jobs=None`)\n",
    "nx.config.backends.parallel.n_jobs = 4\n",
    "\n",
    "### carry weights over to line graph\n",
    "H = nx.line_graph(g)\n",
    "H.add_nodes_from((node, g.edges[node]) for node in H)   \n",
    "\n",
    "for s, t, v in H.edges:\n",
    "    H.edges[(s, t, v)]['weight'] = g.edges[s]['length'] + g.edges[t]['length']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def calc_bc(shortest_paths, graph):\n",
    "    bc = {i : 0 for i in graph.nodes}\n",
    "    for node in tqdm.tqdm(graph.nodes):\n",
    "        for other_node in shortest_paths[node].keys():\n",
    "            path = set(shortest_paths[node][other_node])\n",
    "            for node_visited in path:\n",
    "                bc[node_visited] += 1\n",
    "    for node in bc.keys():\n",
    "        bc[node] /= graph.number_of_nodes()**2\n",
    "    return bc\n",
    "\n",
    "ebc = dict(nxp.all_pairs_dijkstra_path(H, weight='weight',\n",
    "                                        cutoff=1000,\n",
    "                                        ))\n",
    "bc = calc_bc(ebc, H)\n",
    "# bc = {k: v for k, v in sorted(bc.items(), key=lambda item: item[1], reverse=True)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### color edges in g by bc\n",
    "bc2 = {}\n",
    "for x, y, z in bc:\n",
    "    bc2[(x, y)] = bc[(x, y, z)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges, _ = mp.nx_to_gdf(g, points=True, lines=True, spatial_weights=True)\n",
    "\n",
    "nodes.to_file('../data/g_nodes.gpkg', driver='GPKG')\n",
    "edges.to_file('../data/g_edges.gpkg', driver='GPKG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slope_df = gpd.read_file('../data/graphs/edge_slopes.gpkg', layer='Edges average slope')\n",
    "\n",
    "# g_linestrings = [t['geometry'] for s, v, t in H.nodes(data=True)]\n",
    "\n",
    "# for max_slope, linestring in zip(slope_df.max_slope ,slope_df.geometry):\n",
    "#     if linestring in g_linestrings:\n",
    "#         slope = slope_df[slope_df.geometry == linestring].slope.values[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (s, t), value in bc2.items():\n",
    "    for i in range(len(g[s][t])):\n",
    "        g[s][t][i]['bc'] = value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter data assignment\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges = mp.nx_to_gdf(g)\n",
    "\n",
    "import geopandas as gpd \n",
    "import pandas as pd \n",
    "\n",
    "filepath = '/Users/christianrasmussen/Documents/thesis/bike-flow-estimate/data/raw/trafiktaelling.json'\n",
    "\n",
    "gdf = gpd.GeoDataFrame.from_file(filepath)\n",
    "gdf.set_crs(epsg=4326, inplace=True)\n",
    "gdf['geometry'] = gdf['geometry']\n",
    "\n",
    "### export only relevant columns\n",
    "gdf_new = gdf[['id', 'vejnavn', 'geometry', 'aadt_cykler']]\n",
    "\n",
    "### remove null values on aadt_cykler\n",
    "gdf_new = gdf_new[gdf_new['aadt_cykler'].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "linestrings = [i[2]['geometry'] if 'geometry' in i[2] else None for i in list(g.edges(data=True))]\n",
    "from_node = [i[0] for i in list(g.edges(data=True))]\n",
    "to_node = [i[1] for i in list(g.edges(data=True))]\n",
    "\n",
    "def find_nearest_edge(linestrings, point, from_node, to_node):\n",
    "    # Initialize variables to find the closest edge\n",
    "    shortest_distance = float('inf')\n",
    "    closest_edge = None\n",
    "    node_pair = None\n",
    "    for linestring, n1, n2 in zip(linestrings, from_node, to_node): \n",
    "        if linestring is not None:\n",
    "            # Calculate the distance between the point and the edge\n",
    "            distance = linestring.distance(point)\n",
    "            if distance < shortest_distance:\n",
    "                shortest_distance = distance\n",
    "                closest_edge = linestring\n",
    "                node_pair = (n1, n2)\n",
    "    return closest_edge, shortest_distance, node_pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = g.copy()\n",
    "import tqdm\n",
    "for i, row in tqdm.tqdm(gdf_new.iterrows(), total=len(gdf_new)):\n",
    "    point = row['geometry']\n",
    "    closest_edge, shortest_distance, node_pair = find_nearest_edge(linestrings, point, from_node, to_node)\n",
    "    try:\n",
    "        if not 'aadt' in g2[node_pair[0]][node_pair[1]][0].keys():\n",
    "            g2[node_pair[0]][node_pair[1]][0]['aadt'] = row['aadt_cykler']\n",
    "            g2[node_pair[0]][node_pair[1]][0]['aadt_dist'] = shortest_distance\n",
    "        elif g2[node_pair[0]][node_pair[1]][0]['aadt_dist'] > shortest_distance:\n",
    "            print('IT HAPPENED!!!')\n",
    "            g2[node_pair[0]][node_pair[1]][0]['aadt'] = row['aadt_cykler']\n",
    "            g2[node_pair[0]][node_pair[1]][0]['aadt_dist'] = shortest_distance\n",
    "    except:\n",
    "        print(node_pair)\n",
    "        print(row['aadt_cykler'])\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, t, value in g2.edges(data=True):\n",
    "    if 'aadt' not in value.keys():\n",
    "        value['aadt'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/graphs/graph_nx.pkl', 'wb') as f:\n",
    "    pickle.dump(g2, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Torch Graph from **edgelist**\n",
    "\n",
    "To be used as we convert graphs with calculated betweenness centralities and run our GCN over them. <br>\n",
    "**TODO: Functionize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/graphs/graph_nx.pkl', 'rb') as f:\n",
    "    g2 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = []\n",
    "for s, t, v in list(g2.edges(data=True)):\n",
    "    edge_list.append(((s, t), (v['bc'], int(v['aadt']))))\n",
    "\n",
    "# Step 1: Create node mapping (string -> integer)\n",
    "node_to_idx = {}\n",
    "for (src, tgt), _ in edge_list:\n",
    "    if src not in node_to_idx:\n",
    "        node_to_idx[src] = len(node_to_idx)\n",
    "    if tgt not in node_to_idx:\n",
    "        node_to_idx[tgt] = len(node_to_idx)\n",
    "\n",
    "# Step 2: Extract edge index and features\n",
    "edge_index = []\n",
    "edge_attr = []\n",
    "\n",
    "for (src, tgt), feature in edge_list:\n",
    "    edge_index.append([node_to_idx[src], node_to_idx[tgt]])\n",
    "    edge_attr.append(feature)\n",
    "\n",
    "# Convert to torch tensors\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t()  # Shape: [2, num_edges]\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)  # Shape: [num_edges, feature_dim]\n",
    "\n",
    "# Create graph object\n",
    "graph = Data()\n",
    "graph['node'] = torch.arange(len(node_to_idx))  # Add arbitrary node features\n",
    "graph.edge_index = edge_index\n",
    "graph.edge_attr = edge_attr[:, 0].unsqueeze(1)  # Use edge attribute as feature\n",
    "graph.edge_label = edge_attr[:, 1].unsqueeze(1)  # Use edge attribute as label\n",
    "\n",
    "# Print output\n",
    "print(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/graphs/graph_tg.pkl', 'wb') as f:\n",
    "    pickle.dump(graph, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('../data/graphs/graph_nx.pkl', 'wb') as f:\n",
    "    pickle.dump(g, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating torch-geometric GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### carry weights over to line graph\n",
    "H = nx.line_graph(g2)\n",
    "H.add_nodes_from((node, g2.edges[node]) for node in H)\n",
    "for s, t, v in H.edges:\n",
    "    H.edges[(s, t, v)]['weight'] = g2.edges[s]['length'] + g2.edges[t]['length']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amenities = amenities.reset_index()\n",
    "nodes = list((node, linestring) for node, linestring in H.nodes(data='geometry'))\n",
    "nodes = [node for node in nodes if node[1] is not None]\n",
    "linestrings = [linestring for node, linestring in nodes]\n",
    "nodes = [node for node, linestring in nodes]\n",
    "assert len(nodes) == len(linestrings)\n",
    "amenities['geometry'] = amenities['geometry'].apply(lambda x: x.centroid if x.geom_type == 'Polygon' else x)\n",
    "tree = STRtree(linestrings)\n",
    "for geom, amenity in zip(amenities['geometry'], amenities['amenity']):\n",
    "    nearest = tree.nearest(geom)\n",
    "    nearest = nodes[nearest]\n",
    "    if 'amenity' not in H.nodes[nearest]:\n",
    "        H.nodes[nearest]['amenity'] = [amenity]\n",
    "    else:\n",
    "        H.nodes[nearest]['amenity'].append(amenity)\n",
    "\n",
    "from collections import Counter\n",
    "for i in H.nodes(data=True):\n",
    "    if 'amenity' in i[1]:\n",
    "        amenity_counts = Counter(i[1]['amenity'])\n",
    "        for key in amenity_counts:\n",
    "            H.nodes[i[0]][key] = amenity_counts[key]\n",
    "        ## drop the amenity key\n",
    "        H.nodes[i[0]].pop('amenity', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/graphs/linegraph_nx.pkl', 'wb') as f:\n",
    "    g = pickle.dump(H, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in H.nodes(data=True):\n",
    "    node[1].pop('geometry', None)\n",
    "    node[1].pop('osmid', None)\n",
    "    node[1].pop('name', None)\n",
    "    node[1].pop('highway', None)\n",
    "    node[1].pop('ref', None)\n",
    "    node[1].pop('aadt_dist', None)\n",
    "    for key in list(node[1].keys()):\n",
    "        if type(node[1][key]) not in (int, float):\n",
    "            try:\n",
    "                node[1][key] = float(node[1][key])\n",
    "            except:\n",
    "                node[1].pop(key, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = []\n",
    "for node in H.nodes(data=True):\n",
    "    for key in node[1].keys():\n",
    "        if key not in all_feats:\n",
    "            all_feats.append(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in H.nodes(data=True):\n",
    "    for feat in all_feats:\n",
    "        if feat not in node[1].keys():\n",
    "            node[1][feat] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list, x, y = [], [], []\n",
    "for node, feats in list(H.nodes(data=True)):\n",
    "    node_list.append(node)\n",
    "    x.append([feats[feat] for feat in all_feats if feat != 'aadt'])\n",
    "    y.append(feats['aadt'])\n",
    "\n",
    "node_idx = {node : idx for idx, node in enumerate(node_list)}\n",
    "edge_index = []\n",
    "for s, t, _ in list(H.edges):\n",
    "    edge_index.append([node_idx[s], node_idx[t]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.float)\n",
    "\n",
    "linegraph = Data()\n",
    "linegraph.num_nodes = len(node_list)\n",
    "# linegraph['node'] = torch.arange(len(node_list))\n",
    "linegraph.x = x\n",
    "linegraph.y = y\n",
    "linegraph.edge_index = edge_index\n",
    "\n",
    "# with open('../data/graphs/linegraph_tg.pkl', 'wb') as f:\n",
    "    # pickle.dump(linegraph, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linegraph.x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(H.nodes(data=True))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linegraph.x[0].squeeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
