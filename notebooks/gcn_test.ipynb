{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline GCN testing\n",
    "Notebook to create and evaluate GCN against EBC on predicting number of passing bicyclists in *copenhagen?*\n",
    "- Preprocess EBC for graph DONE\n",
    "- Assign Metrics from data\n",
    "- Create Torch Graph\n",
    "- Evaluate against SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric as tg\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import shapely\n",
    "import momepy as mp \n",
    "import esda\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "lat, lon = 55.6867243, 12.5700724\n",
    "\n",
    "def get_city_graph(lat, lon, dist, polygonize=False, plot = False):\n",
    "    g = ox.graph_from_point((lat, lon), dist=dist, network_type='bike', simplify=True, retain_all=False)\n",
    "    gdf = mp.nx_to_gdf(g)\n",
    "    edges = gdf[1].to_crs('EPSG:3857')\n",
    "    if polygonize:\n",
    "        linestrings = edges.geometry # our geopandas.GeoSeries of linestrings representing street network\n",
    "        collection = shapely.GeometryCollection(linestrings.array)  # combine to a single object\n",
    "        noded = shapely.node(collection)  # add missing nodes\n",
    "        polygonized = shapely.polygonize(noded.geoms)  # polygonize based on an array of noded parts\n",
    "        polygons = gpd.GeoSeries(polygonized.geoms)  # create a GeoSeries from parts\n",
    "        return g, edges, polygons\n",
    "    if plot:\n",
    "        ### plot the graph\n",
    "        fig, ax = ox.plot_graph(g, node_size=0, edge_linewidth=0.5, show=False, close=False)\n",
    "        edges.plot(ax=ax, linewidth=1, edgecolor='black')\n",
    "        plt.show()\n",
    "    return g, edges\n",
    "\n",
    "g, edges = get_city_graph(lat, lon, 10000)\n",
    "\n",
    "### plot the graph\n",
    "fig, ax = ox.plot_graph(g, node_size=0, edge_linewidth=0.5, show=False, close=False)\n",
    "edges.plot(ax=ax, linewidth=1, edgecolor='black')\n",
    "\n",
    "import nx_parallel as nxp\n",
    "import networkx as nx\n",
    "\n",
    "# enabling networkx's config for nx-parallel\n",
    "nx.config.backends.parallel.active = True\n",
    "\n",
    "# setting `n_jobs` (by default, `n_jobs=None`)\n",
    "nx.config.backends.parallel.n_jobs = 4\n",
    "\n",
    "### carry weights over to line graph\n",
    "H = nx.line_graph(g)\n",
    "H.add_nodes_from((node, g.edges[node]) for node in H)   \n",
    "\n",
    "for s, t, v in H.edges:\n",
    "    H.edges[(s, t, v)]['weight'] = g.edges[s]['length'] + g.edges[t]['length']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bc(shortest_paths, graph):\n",
    "    bc = {i : 0 for i in graph.nodes}\n",
    "    for node in (graph.nodes):\n",
    "        for other_node in shortest_paths[node].keys():\n",
    "            path = shortest_paths[node][other_node]\n",
    "            for node_visited in path:\n",
    "                bc[node_visited] += 1\n",
    "    for node in bc.keys():\n",
    "        bc[node] /= len(graph.nodes)\n",
    "    return bc\n",
    "\n",
    "ebc = dict(nxp.all_pairs_dijkstra_path(H, weight='weight', cutoff=1000))\n",
    "bc = calc_bc(ebc, H)\n",
    "bc = {k: v for k, v in sorted(bc.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "\n",
    "### color edges in g by bc\n",
    "bc2 = {}\n",
    "for x, y, z in bc:\n",
    "    bc2[(x, y)] = bc[(x, y, z)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (s, t), value in bc2.items():\n",
    "    for i in range(len(g[s][t])):\n",
    "        g[s][t][i]['bc'] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_copy = g.copy()\n",
    "# for node in list(g_copy.nodes(data=True)):\n",
    "#     for key in list(node[1].keys()):\n",
    "#         del node[1][key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter data assignment\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges = mp.nx_to_gdf(g)\n",
    "\n",
    "import geopandas as gpd \n",
    "import pandas as pd \n",
    "\n",
    "filepath = '/Users/christianrasmussen/Documents/thesis/bike-flow-estimate/data/raw/trafiktaelling.json'\n",
    "\n",
    "gdf = gpd.GeoDataFrame.from_file(filepath)\n",
    "gdf.set_crs(epsg=4326, inplace=True)\n",
    "gdf['geometry'] = gdf['geometry'].to_crs(epsg=4326)\n",
    "\n",
    "### export only relevant columns\n",
    "gdf_new = gdf[['id', 'vejnavn', 'geometry', 'aadt_cykler']]\n",
    "### remove null values on aadt_cykler\n",
    "gdf_new = gdf_new[gdf_new['aadt_cykler'].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "linestrings = [i[2]['geometry'] if 'geometry' in i[2] else None for i in list(g.edges(data=True))]\n",
    "from_node = [i[0] for i in list(g.edges(data=True))]\n",
    "to_node = [i[1] for i in list(g.edges(data=True))]\n",
    "g = nx.Graph(g)\n",
    "\n",
    "def find_nearest_edge(linestrings, point, from_node, to_node):\n",
    "    # Initialize variables to find the closest edge\n",
    "    shortest_distance = float('inf')\n",
    "    closest_edge = None\n",
    "    node_pair = None\n",
    "    for linestring, n1, n2 in zip(linestrings, from_node, to_node): \n",
    "        if linestring is not None:\n",
    "            # Calculate the distance between the point and the edge\n",
    "            distance = linestring.distance(point)\n",
    "            if distance < shortest_distance:\n",
    "                shortest_distance = distance\n",
    "                closest_edge = linestring\n",
    "                node_pair = (n1, n2)\n",
    "    return closest_edge, shortest_distance, node_pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = g.copy()\n",
    "import tqdm\n",
    "for i, row in tqdm.tqdm(gdf_new.iterrows(), total=len(gdf_new)):\n",
    "    point = row['geometry']\n",
    "    closest_edge, shortest_distance, node_pair = find_nearest_edge(linestrings, point, from_node, to_node)\n",
    "    try:\n",
    "        g2[node_pair[0]][node_pair[1]]['aadt'] = row['aadt_cykler']\n",
    "    except:\n",
    "        print(node_pair)\n",
    "        print(row['aadt_cykler'])\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in g2.edges(data=True):\n",
    "    if 'aadt' not in edge[2]:\n",
    "        g2[edge[0]][edge[1]]['aadt'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(list(g2.edges(data=True))):\n",
    "    if i[2]['aadt'] > 0:\n",
    "        print(idx)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(gdf_new['aadt_cykler'].isna()))\n",
    "gdf_new['aadt_cykler'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Torch Graph from **edgelist**\n",
    "\n",
    "To be used as we convert graphs with calculated betweenness centralities and run our GCN over them. <br>\n",
    "**TODO: Functionize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = []\n",
    "for s, t, v in list(g2.edges(data=True)):\n",
    "    edge_list.append(((s, t), (v['bc'], v['aadt'])))\n",
    "\n",
    "# Step 1: Create node mapping (string -> integer)\n",
    "node_to_idx = {}\n",
    "for (src, tgt), _ in edge_list:\n",
    "    if src not in node_to_idx:\n",
    "        node_to_idx[src] = len(node_to_idx)\n",
    "    if tgt not in node_to_idx:\n",
    "        node_to_idx[tgt] = len(node_to_idx)\n",
    "\n",
    "# Step 2: Extract edge index and features\n",
    "edge_index = []\n",
    "edge_attr = []\n",
    "\n",
    "for (src, tgt), feature in edge_list:\n",
    "    edge_index.append([node_to_idx[src], node_to_idx[tgt]])\n",
    "    edge_attr.append(feature)\n",
    "\n",
    "# Convert to torch tensors\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t()  # Shape: [2, num_edges]\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)  # Shape: [num_edges, feature_dim]\n",
    "\n",
    "# Create graph object\n",
    "graph = Data(edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# Print output\n",
    "print(graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating torch-geometric GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set column 1 as x feature\n",
    "graph.x = torch.tensor(edge_attr[:, 0], dtype=torch.float).reshape(-1, 1)\n",
    "\n",
    "## set column 2 as y feature\n",
    "graph.y = torch.tensor(edge_attr[:, 1], dtype=torch.float).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('../data/graphs/graph.pkl', 'wb') as f:\n",
    "    pickle.dump(graph, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create edge sampling loader\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1)(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
